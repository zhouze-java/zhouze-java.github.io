<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Elasticsearch-51-cross-fields搜索问题解决方案]]></title>
    <url>%2F2018%2F12%2F19%2FElasticsearch-51-cross-fields%E6%90%9C%E7%B4%A2%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[解决方案一:使用copy_to用copy_to可以将多个field组合成一个field. 之前说的问题,其实就是出在了有多个field,那么我们只要把这些field合并成一个field即可,比如搜索一个人名,有first_name和last_name,将这两个field合并成一个full_name就可以解决了 示例首先,创建三个field: new_author_first_name , new_author_last_name , new_author_full_name12345678910111213141516PUT /forum/_mapping/article&#123; &quot;properties&quot;: &#123; &quot;new_author_first_name&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;copy_to&quot;: &quot;new_author_full_name&quot; &#125;, &quot;new_author_last_name&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;copy_to&quot;: &quot;new_author_full_name&quot; &#125;, &quot;new_author_full_name&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &#125;&#125; new_author_first_name和new_author_last_name都设置copy_to到new_author_full_name中去,用了这个copy_to语法之后,就可以将多个字段的值拷贝到一个字段中,并建立倒排索引 添加数据1234567891011POST /forum/article/_bulk&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;new_author_first_name&quot; : &quot;Peter&quot;, &quot;new_author_last_name&quot; : &quot;Smith&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;2&quot;&#125; &#125; &#123; &quot;doc&quot; : &#123;&quot;new_author_first_name&quot; : &quot;Smith&quot;, &quot;new_author_last_name&quot; : &quot;Williams&quot;&#125; &#125; &#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;3&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;new_author_first_name&quot; : &quot;Jack&quot;, &quot;new_author_last_name&quot; : &quot;Ma&quot;&#125; &#125; &#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;4&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;new_author_first_name&quot; : &quot;Robbin&quot;, &quot;new_author_last_name&quot; : &quot;Li&quot;&#125; &#125; &#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;5&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;new_author_first_name&quot; : &quot;Tonny&quot;, &quot;new_author_last_name&quot; : &quot;Peter Smith&quot;&#125; &#125; 添加完毕后,这时候可以去查询一下全部的数据,返现并没有new_author_full_name这个field,因为这个field就类似于之前有说过的 _all元数据,是不在_source中显示的 接着来查询名称是Peter Smith的数据12345678GET forum/article/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;new_author_full_name&quot;: &quot;Peter Smith&quot; &#125; &#125;&#125; 返回值:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788&#123; &quot;took&quot;: 3, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: 0.62191015, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.62191015, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 50, &quot;title&quot;: &quot;this is java blog&quot;, &quot;content&quot;: &quot;i think java is the best programming language&quot;, &quot;sub_title&quot;: &quot;learned a lot of course&quot;, &quot;author_first_name&quot;: &quot;Smith&quot;, &quot;author_last_name&quot;: &quot;Williams&quot;, &quot;new_author_last_name&quot;: &quot;Williams&quot;, &quot;new_author_first_name&quot;: &quot;Smith&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.51623213, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;hadoop&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 30, &quot;title&quot;: &quot;this is java and elasticsearch blog&quot;, &quot;content&quot;: &quot;i like to write best elasticsearch article&quot;, &quot;sub_title&quot;: &quot;learning more courses&quot;, &quot;author_first_name&quot;: &quot;Peter&quot;, &quot;author_last_name&quot;: &quot;Smith&quot;, &quot;new_author_last_name&quot;: &quot;Smith&quot;, &quot;new_author_first_name&quot;: &quot;Peter&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_score&quot;: 0.5063205, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;DHJK-B-1395-#Ky5&quot;, &quot;userID&quot;: 3, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2018-12-03&quot;, &quot;tag&quot;: [ &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 10, &quot;title&quot;: &quot;this is spark blog&quot;, &quot;content&quot;: &quot;spark is best big data solution based on scala ,an programming language similar to java&quot;, &quot;sub_title&quot;: &quot;haha, hello world&quot;, &quot;author_first_name&quot;: &quot;Tonny&quot;, &quot;author_last_name&quot;: &quot;Peter Smith&quot;, &quot;new_author_last_name&quot;: &quot;Peter Smith&quot;, &quot;new_author_first_name&quot;: &quot;Tonny&quot; &#125; &#125; ] &#125;&#125; 这里的搜索结果还是和之前一样的,因为es的算法的原因,没法实现这个场景,但是copy_to已经把前一节提到的问题解决了 之前的问题一被合并成一个field了,就不存在了,而且这里的查询可以使用minimum_should_match来去长尾,第三个问题Smith和Peter在一个field里面了,所以在所有document中出现的次数是均匀的,不会有极端的偏差 解决方案二:原生cross-fields语法1234567891011GET forum/article/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;Peter Smith&quot;, &quot;fields&quot;: [&quot;author_first_name&quot;,&quot;author_last_name&quot;], &quot;type&quot;: &quot;cross_fields&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125;&#125; 这种方法也可以解决上文提到的那三个问题 cross_fields是要求每个term都必须在任何一个field中出现 这就解决了第一个问题,举个例子:搜索条件还是Peter Smith,按照cross_fields来搜索的话要求Peter必须在author_first_name或author_last_name中出现要求Smith必须在author_first_name或author_last_name中出现Peter Smith可能是横跨在多个field中的,所以必须要求每个term都在某个field中出现,组合起来才能组成我们想要的标识,比如一个完整的人名 原来most-fields搜索的时候,可能像Smith Williams也可能会出现,因为most-fields要求只是任何一个field匹配了就可以,匹配的field越多,分数就越高 第二个问题是most-fields没办法去长尾的问题,用cross_fields的时候,每个term都要求出现,那长尾肯定被干掉了举个例子现在有一个搜索条件是java Hadoop spark 那么这三个term都必须在任何一个filed中出现了比如有的document中,只有一个field中包含一个java,那就被干掉了,作为长尾就没了. 第三个问题,在使用cross-fields查询的时候,es在计算IDF的时候会将每个query在每个filed中的IDF都取出来,取最小值,就不会出现极端情况下的最大值了 举个例子,还是查询Peter SmithSmith,在author_first_name这个field中,在所有document的这个field中,出现的频率很低,导致IDF分数很高;Smith在所有doc的author_last_name field中的频率算出一个IDF分数,因为一般来说last_name中的Smith频率都较高,所以IDF分数是正常的,不会太高;然后对于Smith来说,会取两个IDF分数中较小的那个分数.就不会出现IDF分过高的情况.]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-50-most_fields策略进行cross-fields搜索的弊端]]></title>
    <url>%2F2018%2F12%2F19%2FElasticsearch-50-most-fields%E7%AD%96%E7%95%A5%E8%BF%9B%E8%A1%8Ccross-fields%E6%90%9C%E7%B4%A2%E7%9A%84%E5%BC%8A%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[cross-field搜索就是我们搜索一个唯一标识的时候跨越了多个field,比如一个人,标识是姓名,一个建筑的标识是地址. 姓名可以散落在多个field中,比如first_name和last_name中,地址可以散落在country,province,city中.跨多个field搜索一个标识,就是cross-fields搜索 这个情况下用most-fields搜索就比较合适了,因为best-fields是优先搜索单个field最匹配的结果,cross-fields本身就不是一个field的问题了 案例首先,准备数据1234567891011POST /forum/article/_bulk&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;author_first_name&quot; : &quot;Peter&quot;, &quot;author_last_name&quot; : &quot;Smith&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;2&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;author_first_name&quot; : &quot;Smith&quot;, &quot;author_last_name&quot; : &quot;Williams&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;3&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;author_first_name&quot; : &quot;Jack&quot;, &quot;author_last_name&quot; : &quot;Ma&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;4&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;author_first_name&quot; : &quot;Robbin&quot;, &quot;author_last_name&quot; : &quot;Li&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;5&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;author_first_name&quot; : &quot;Tonny&quot;, &quot;author_last_name&quot; : &quot;Peter Smith&quot;&#125; &#125; 然后来查询一下Peter Smith12345678910GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;Peter Smith&quot;, &quot;fields&quot;: [&quot;author_first_name&quot;,&quot;author_last_name&quot;], &quot;type&quot;: &quot;most_fields&quot; &#125; &#125;&#125; 返回值:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&#123; &quot;took&quot;: 28, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: 0.6931472, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.6931472, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 50, &quot;title&quot;: &quot;this is java blog&quot;, &quot;content&quot;: &quot;i think java is the best programming language&quot;, &quot;sub_title&quot;: &quot;learned a lot of course&quot;, &quot;author_first_name&quot;: &quot;Smith&quot;, &quot;author_last_name&quot;: &quot;Williams&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.5753642, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;hadoop&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 30, &quot;title&quot;: &quot;this is java and elasticsearch blog&quot;, &quot;content&quot;: &quot;i like to write best elasticsearch article&quot;, &quot;sub_title&quot;: &quot;learning more courses&quot;, &quot;author_first_name&quot;: &quot;Peter&quot;, &quot;author_last_name&quot;: &quot;Smith&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_score&quot;: 0.51623213, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;DHJK-B-1395-#Ky5&quot;, &quot;userID&quot;: 3, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2018-12-03&quot;, &quot;tag&quot;: [ &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 10, &quot;title&quot;: &quot;this is spark blog&quot;, &quot;content&quot;: &quot;spark is best big data solution based on scala ,an programming language similar to java&quot;, &quot;sub_title&quot;: &quot;haha, hello world&quot;, &quot;author_first_name&quot;: &quot;Tonny&quot;, &quot;author_last_name&quot;: &quot;Peter Smith&quot; &#125; &#125; ] &#125;&#125; 来看一下返回值, id是2的document被排在了第一位,为什么?因为IDF分数高, document2的author_first_name 是Smith,在所有的doc中只出现过一次,出现的频率低再来看下document1 和 document5 这两个的author_last_name都出现了,所以导致document1的分数要比document2的分数要低 大概来说是这样的,es的算法很复杂,这些都是可能影响分数的. cross-fields问题 只是找到尽可能多的field匹配到的document,而不是某个field完全匹配的document most-fields没办法使用minimum_should_match去掉长尾数据,就是匹配特别少的结果 TF/IDF算法,比如上面搜索中的Peter Smith和Smith Williams,搜索Peter Smith的时候,由于first_name中很少有Smith的,所以在query中所有document中的频率很低,得到的分数很高,可能Smith Williams反而会排在Peter Smith的前面]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-49-实战案例-most-fields策略]]></title>
    <url>%2F2018%2F12%2F17%2FElasticsearch-49-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B-most-fields%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[对比之前我们写了best-fields策略,本文将使用most-fields来搜索,那么两者有什么区别呢?best-fields策略:主要是说,将某一个field匹配尽可能多的关键词document优先返回回来most-fields策略:主要是说将更多filed匹配到某个关键词的document优先返回回来 举例现在有两个document,如下:document1:1234&#123; &quot;title&quot;:&quot;China people&quot;, &quot;content&quot;:&quot;i am a good person&quot;&#125; document2:1234&#123; &quot;title&quot;:&quot;China person&quot;, &quot;content&quot;:&quot;i am a good people&quot;&#125; 一个搜索请求,搜索的关键字是China person,那么来看一下两种搜索策略的返回结果是怎样的 best-fields:会优先将document2返回回来,因为document2的title匹配了两个关键字most-fields:会优先将document1返回回来,因为document1匹配了两个field 实战案例先来准备数据,添加一个sub_title字段,手动创建mapping123456789101112131415POST /forum/_mapping/article&#123; &quot;properties&quot;: &#123; &quot;sub_title&quot;:&#123; &quot;type&quot;: &quot;string&quot;, &quot;analyzer&quot;: &quot;english&quot;, &quot;fields&quot;: &#123; &quot;std&quot;:&#123; &quot;type&quot;: &quot;string&quot;, &quot;analyzer&quot;: &quot;standard&quot; &#125; &#125; &#125; &#125;&#125; 添加数据1234567891011POST /forum/article/_bulk&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;sub_title&quot; : &quot;learning more courses&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;2&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;sub_title&quot; : &quot;learned a lot of course&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;3&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;sub_title&quot; : &quot;we have a lot of fun&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;4&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;sub_title&quot; : &quot;both of them are good&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;5&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;sub_title&quot; : &quot;haha, hello world&quot;&#125; &#125; 搜索查询sub_title中包含learning courses的document12345678GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;sub_title&quot;: &quot;learning courses&quot; &#125; &#125;&#125; 返回值:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&#123; &quot;took&quot;: 4, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 2, &quot;max_score&quot;: 1.219939, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1.219939, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 50, &quot;title&quot;: &quot;this is java blog&quot;, &quot;content&quot;: &quot;i think java is the best programming language&quot;, &quot;sub_title&quot;: &quot;learned a lot of course&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.5063205, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;hadoop&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 30, &quot;title&quot;: &quot;this is java and elasticsearch blog&quot;, &quot;content&quot;: &quot;i like to write best elasticsearch article&quot;, &quot;sub_title&quot;: &quot;learning more courses&quot; &#125; &#125; ] &#125;&#125; 来看一下返回值,这里有个问题,为什么learned a lot of course 排在了 learning more courses 的前面? 在我们手动创建sub_title的mapping映射的时候,使用的是English分词器,所以会还原单词,将单词还原为其最基本的形态(stemmer),比如learning –&gt; learnlearned –&gt; learncourses –&gt; course 所以,我们的搜索条件也会变, learning courses –&gt; learn course,这时候去搜索对于这两个sub_title来说就是一样的,所以就会出现learned a lot of course 排在了 learning more courses 的前面这样的情况 most-fields搜索我们上面在sub_title中还创建了个子field sub_title.std,然后我们用这两个field来进行most-field搜索.请求12345678910GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;learning courses&quot;, &quot;type&quot;: &quot;most_fields&quot;, &quot;fields&quot;: [&quot;sub_title&quot;,&quot;sub_title.std&quot;] &#125; &#125;&#125; 返回值:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&#123; &quot;took&quot;: 3, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 2, &quot;max_score&quot;: 1.219939, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1.219939, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 50, &quot;title&quot;: &quot;this is java blog&quot;, &quot;content&quot;: &quot;i think java is the best programming language&quot;, &quot;sub_title&quot;: &quot;learned a lot of course&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1.012641, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;hadoop&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 30, &quot;title&quot;: &quot;this is java and elasticsearch blog&quot;, &quot;content&quot;: &quot;i like to write best elasticsearch article&quot;, &quot;sub_title&quot;: &quot;learning more courses&quot; &#125; &#125; ] &#125;&#125; 再来看一下返回值,依然是learned a lot of course排在了前面,但是learning more courses的分数有了大幅度的提高,可以对比一下第一个搜索时候的分数 区别和优缺点best-fields,是对多个field进行搜索,挑选某个filed匹配度最高的那个分数,同时在多个query最高分相同的情况下,在一定程度上考虑其他query的分数. 简单来说就是,对多个filed进行搜索,就想搜索到某一个field尽可能包含更多关键字的数据 优点:通过best_fields策略,以及综合考虑其他field,还有minimum_should_match支持,可以尽可能精准的将匹配的结果推送到最前面缺点:除了那些精准匹配的结果,其他差不多大的结果,排序结果不是太均匀,没有什么区分度了 most-fields,综合多个field一起进行搜索,尽可能多地让所有的field的query参与到总分数的计算中来,此时就会是个大杂烩,数显类似best_fields案例最开始的那个结果,结果不一定精准,某一个document的一个field包含更多的关键字,但是因为其他document有更多field匹配到了,所以排在前面, 所以就需要建立类似sub_title.std这样的field,尽可能让某一个field精准匹配query string,贡献更高的分数,将更精准匹配的数据排到前面 优点:将尽可能匹配更多的field的结果推送到前面,整个排序的结果都是比较均匀的缺点:可能那些精准匹配的结果无法排在最前面 实际的例子:wiki,明显的most_fields策略,搜索结果比较均匀,但是的确要翻好几页才能找到最匹配的结果]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-48-multi_match语法]]></title>
    <url>%2F2018%2F12%2F17%2FElasticsearch-48-multi-match%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[minimum_should_match作用我们先来看一个查询123456789101112131415161718192021222324252627GET forum/article/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; &quot;queries&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &#123; &quot;query&quot;: &quot;java beginner&quot;, &quot;minimum_should_match&quot;:&quot;50%&quot;, &quot;boost&quot;:2 &#125; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;content&quot;: &#123; &quot;query&quot;: &quot;java beginner&quot;, &quot;minimum_should_match&quot;:&quot;30%&quot; &#125; &#125; &#125; ], &quot;tie_breaker&quot;: 0.3 &#125; &#125;&#125; 上面这个查询就是查询了title或者content中包含java beginner的内容,用了dis_max+tie_breaker查询,而且查询title的权重是2,还有一个搜索参数是 “minimum_should_match”,那么这个关键字是做什么用的呢 minimum_should_match: 去长尾,比如你搜素5个关键词,但是很多结果是只匹配一个关键词的,其实跟你想要的结果相差甚远,这些结果就是长尾minimum_should_match,可以控制搜索结果的精准度,只有匹配一定数量的关键词数据,才能返回 multi_match语法123456789101112GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;java beginner&quot;, &quot;type&quot;: &quot;best_fields&quot;, &quot;fields&quot;: [&quot;title^2&quot;,&quot;content&quot;], &quot;tie_breaker&quot;: 0.3, &quot;minimum_should_match&quot;:&quot;50%&quot; &#125; &#125;&#125; type: 默认就是best_fields查询title^2: 代表title的权重是2, 相当于上面的”boost”:2]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-47-实战案例-基于dis_max实现best fileds策略进行多字段搜索]]></title>
    <url>%2F2018%2F12%2F06%2FElasticsearch-47-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B-%E5%9F%BA%E4%BA%8Edis-max%E5%AE%9E%E7%8E%B0best-fileds%E7%AD%96%E7%95%A5%E8%BF%9B%E8%A1%8C%E5%A4%9A%E5%AD%97%E6%AE%B5%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[准备工作为帖子增加content字段1234567891011POST /forum/article/_bulk&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;content&quot; : &quot;i like to write best elasticsearch article&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;2&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;content&quot; : &quot;i think java is the best programming language&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;3&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;content&quot; : &quot;i am only an elasticsearch beginner&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;4&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;content&quot; : &quot;elasticsearch and hadoop are all very good solution, i am a beginner&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;5&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;content&quot; : &quot;spark is best big data solution based on scala ,an programming language similar to java&quot;&#125; &#125; 需求一搜索title或content中包含java或solution的帖子构建搜索条件12345678910111213141516171819GET forum/article/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;java solution&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;java solution&quot; &#125; &#125; ] &#125; &#125;&#125; 返回值:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&#123; &quot;took&quot;: 23, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 4, &quot;max_score&quot;: 0.8849759, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.8849759, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 50, &quot;title&quot;: &quot;this is java blog&quot;, &quot;content&quot;: &quot;i think java is the best programming language&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 0.7120095, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;QQPX-R-3956-#aD8&quot;, &quot;userID&quot;: 2, &quot;hidden&quot;: true, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 80, &quot;title&quot;: &quot;this is java, elasticsearch, hadoop blog&quot;, &quot;content&quot;: &quot;elasticsearch and hadoop are all very good solution, i am a beginner&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_score&quot;: 0.56008905, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;DHJK-B-1395-#Ky5&quot;, &quot;userID&quot;: 3, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2018-12-03&quot;, &quot;tag&quot;: [ &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 10, &quot;title&quot;: &quot;this is spark blog&quot;, &quot;content&quot;: &quot;spark is best big data solution based on scala ,an programming language similar to java&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.26742277, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;hadoop&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 30, &quot;title&quot;: &quot;this is java and elasticsearch blog&quot;, &quot;content&quot;: &quot;i like to write best elasticsearch article&quot; &#125; &#125; ] &#125;&#125; 我们来看一下返回值:排在第一位的是id是2的document,这个document中只有title包含了java,content也包含了java排在第二位的是id是4的document,这document中,是title中包含了java,content中包含了solution排在第三位的是id是5的document,这个document中,是content包含了java和solution 这样看来应该是id=5的document是相关度比id=4的高的,但是id=4的排在了前面,这是为什么呢? es的计算方式es在计算每个document的relevance score是每个query的分数的和,乘以matched query的数量,除以总query的数量对于每个query(就是上面should中的每个match),es都会计算一个数量, matched query 就是匹配到的条件的数量 我们来算一下id=4 的document的分数,查询中的两个条件{ “match”: { “title”: “java solution” }},针对document4 是有一个分数的,假设是1.1{ “match”: { “content”: “java solution” }}，针对document4,也是有一个分数的,假设是1.2query分数的和1.1 + 1.2 = 2.3,matched query的数量是2, 总共的query数量是2,所以计算出来就是2.3 * 2 / 2 = 2.3 我们再来算一下document 5 的分数,查询中的两个条件{ “match”: { “title”: “java solution” }},针对document5 是没有分数的,因为这个条件不匹配document5{ “match”: { “content”: “java solution” }}，针对document5,也是有一个分数的,假设是2.3这时候query分数的总和就是2.3,matched query的数量是1,总共的query数量是2,所以计算出来就是 2.3 * 1 / 2 = 1.15 2.3 &gt; 1.15 所以document4 排在了document5的前面 best fields策略 dis_maxbest fields策略: 就是说,搜索到的结果应该是某一个匹配到尽可能多的关键词的document被排在前面,而不是匹配到了少数的关键词还排在前面 搜索请求:12345678910111213141516171819GET forum/article/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; &quot;queries&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;java solution&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;java solution&quot; &#125; &#125; ] &#125; &#125;&#125; 返回值:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&#123; &quot;took&quot;: 6, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 4, &quot;max_score&quot;: 0.68640786, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.68640786, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 50, &quot;title&quot;: &quot;this is java blog&quot;, &quot;content&quot;: &quot;i think java is the best programming language&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_score&quot;: 0.56008905, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;DHJK-B-1395-#Ky5&quot;, &quot;userID&quot;: 3, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2018-12-03&quot;, &quot;tag&quot;: [ &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 10, &quot;title&quot;: &quot;this is spark blog&quot;, &quot;content&quot;: &quot;spark is best big data solution based on scala ,an programming language similar to java&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 0.5565415, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;QQPX-R-3956-#aD8&quot;, &quot;userID&quot;: 2, &quot;hidden&quot;: true, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 80, &quot;title&quot;: &quot;this is java, elasticsearch, hadoop blog&quot;, &quot;content&quot;: &quot;elasticsearch and hadoop are all very good solution, i am a beginner&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.26742277, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;hadoop&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 30, &quot;title&quot;: &quot;this is java and elasticsearch blog&quot;, &quot;content&quot;: &quot;i like to write best elasticsearch article&quot; &#125; &#125; ] &#125;&#125; 可以看到,这次查询document5排在了document4的前面 dis_max语法,直接取多个query中,分数最高的那个query的分数即可,我们来分析一下:{ “match”: { “title”: “java solution” }},针对document4,是有一个分数的,比如1.1{ “match”: { “content”: “java solution” }},针对document4,也是有一个分数的,比如1.2取最大分数,1.2 { “match”: { “title”: “java solution” }},针对doc5,是没有分数的{ “match”: { “content”: “java solution” }}，针对doc5,是有一个分数的,比如2.3取最大分数,2.3 然后document4的分数 = 1.2 &lt; document5的分数 = 2.3,所以document5就可以排在更前面的地方,符合我们的需要 基于tie_breaker参数优化dis_max搜索效果场景搜索条件:搜索title或content中包含java beginner的帖子 假设我们现在有3个documentdocument1:title中包含java,content不包含 java beginner任何一个关键词document2:title中不包含任何一个关键词,content中包含beginnerdocument3:title中包含java,content中包含beginner 这时候执行搜索,可能出现的结果是document1和document2排在了document3的前面,而我们期望的是document3排在最前面 dis_max是只取一个query最大的分数,完全不考虑其他的query的分数 使用tie_breaker优化结果tie_breaker参数的意义在于,将其他的query分数,乘以tie_breaker,然后综合在一起计算,除了取最高分以外,还会考虑其他的query分数 tie_breaker的值在0-1之间 用法示例:1234567891011121314151617181920GET forum/article/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; &quot;queries&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;java beginner&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;java beginner&quot; &#125; &#125; ], &quot;tie_breaker&quot;:0.3 &#125; &#125;&#125; 跟queries是同级的, 可以去试一下加tie_breaker和不加时候查询的分数,对比一下就很清楚了,这里就不去演示了]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-46-多shard场景下relevance score不准确的问题]]></title>
    <url>%2F2018%2F12%2F05%2FElasticsearch-46-%E5%A4%9Ashard%E5%9C%BA%E6%99%AF%E4%B8%8Brelevance-score%E4%B8%8D%E5%87%86%E7%A1%AE%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[场景一个index的数据被分配到了多个shard上,每个shard都包含一部分这个index的数据如图所示,一个搜索请求条件是title中包含java,假如shard1 上面有10条符合条件的document,这个请求到达shard1上的时候,默认是在这个shard本地local去进行IDF计算在shard2中假如只有1个符合条件的数据,那shard2也会在local计算他的IDF,这时候这个分数就会算的很高 问题有时候导致出现的搜索结果,似乎不是你想要的结果,也许相关度高的document被排在了后面,很低的被排在了前面但是他的分数很高 解决方案生产环境生产环境中,数据量很大的话,在概率学的背景下,一般情况中es都是在多个shard中均匀的路由数据的,比如说有10个document,title都包含java,一共有5个shard,那么在概率学的背景下,如果负载均衡的话,其实每个shard都应该有2个document的title包含java如果说数据分布均匀的话,就没有上面说的问题了 测试环境测试环境下,可以将所有的primary shard个数设置为1,只有一个shard的话,所有的document都在这一个shard上面,就没有这个问题了 也可以在搜索时附带search_type=dfs_query_then_fetch参数计算一个doc的相关度分数的时候,就会将所有shard对的local IDF计算一下,获取出来,在本地进行global IDF分数的计算,会将所有shard的doc作为上下文来进行计算,也能确保准确性.但是production生产环境下,不推荐这个参数,因为性能很差]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-45-实战案例-基于boost的细粒度搜索条件权重控制]]></title>
    <url>%2F2018%2F12%2F05%2FElasticsearch-45-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B-%E5%9F%BA%E4%BA%8Eboost%E7%9A%84%E7%BB%86%E7%B2%92%E5%BA%A6%E6%90%9C%E7%B4%A2%E6%9D%A1%E4%BB%B6%E6%9D%83%E9%87%8D%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[场景我们来搜索一下标题必须包含 “blog” 的数据,然后可以包含 “java” “hadoop” “elasticsearch” “spark”的数据 实现组合搜索条件123456789101112131415161718192021222324252627282930313233343536GET forum/article/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;blog&quot; &#125; &#125; ], &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;java&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;elasticsearch&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;hadoop&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;spark&quot; &#125; &#125; ] &#125; &#125;&#125; 返回值:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107&#123; &quot;took&quot;: 43, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 5, &quot;max_score&quot;: 1.4930474, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 1.4930474, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;QQPX-R-3956-#aD8&quot;, &quot;userID&quot;: 2, &quot;hidden&quot;: true, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 80, &quot;title&quot;: &quot;this is java, elasticsearch, hadoop blog&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.80226827, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;hadoop&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 30, &quot;title&quot;: &quot;this is java and elasticsearch blog&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_score&quot;: 0.5753642, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;DHJK-B-1395-#Ky5&quot;, &quot;userID&quot;: 3, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2018-12-03&quot;, &quot;tag&quot;: [ &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 10, &quot;title&quot;: &quot;this is spark blog&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 0.5753642, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;JODL-X-1937-#pV7&quot;, &quot;userID&quot;: 2, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;hadoop&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 100, &quot;title&quot;: &quot;this is elasticsearch blog&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.3971361, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 50, &quot;title&quot;: &quot;this is java blog&quot; &#125; &#125; ] &#125;&#125; 看一下返回结果, 5条数据都返回来了, 排在第一位的数据的title是 “this is java, elasticsearch, hadoop blog”,因为这条数据满足的条件最多,所以排在第一位 权重控制给每个条件一个权重值,boost, boost越大这个搜索条件的权重越大 现在 我们给”spark”,这个条件设置一个权重123456789101112131415161718192021222324252627282930313233343536373839GET forum/article/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;blog&quot; &#125; &#125; ], &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;java&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;elasticsearch&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;hadoop&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;title&quot;: &#123; &quot;query&quot;: &quot;spark&quot;, &quot;boost&quot;:5 &#125; &#125; &#125; ] &#125; &#125;&#125; 返回值:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107&#123; &quot;took&quot;: 8, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 5, &quot;max_score&quot;: 1.7260925, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_score&quot;: 1.7260925, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;DHJK-B-1395-#Ky5&quot;, &quot;userID&quot;: 3, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2018-12-03&quot;, &quot;tag&quot;: [ &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 10, &quot;title&quot;: &quot;this is spark blog&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 1.4930474, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;QQPX-R-3956-#aD8&quot;, &quot;userID&quot;: 2, &quot;hidden&quot;: true, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 80, &quot;title&quot;: &quot;this is java, elasticsearch, hadoop blog&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.80226827, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;hadoop&quot; ], &quot;tag_cnt&quot;: 2, &quot;view_cnt&quot;: 30, &quot;title&quot;: &quot;this is java and elasticsearch blog&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 0.5753642, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;JODL-X-1937-#pV7&quot;, &quot;userID&quot;: 2, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;hadoop&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 100, &quot;title&quot;: &quot;this is elasticsearch blog&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.3971361, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 50, &quot;title&quot;: &quot;this is java blog&quot; &#125; &#125; ] &#125;&#125; 可以看到,搜索结果中包含spark的这个document排到了最前面, es在计算 relevance score 的时候,匹配权重更大的搜索条件的document,relevance score会更高,当然也会优先返回回来默认情况下,所有的搜索条件的权重都是1]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-44-基于term+bool实现的multi word搜索底层原理剖析]]></title>
    <url>%2F2018%2F12%2F04%2FElasticsearch-44-%E5%9F%BA%E4%BA%8Eterm-bool%E5%AE%9E%E7%8E%B0%E7%9A%84multi%20word%E6%90%9C%E7%B4%A2%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在我们使用match这种查询的时候,在es底层其实会自动的转换成term+bool的这种查询 示例一原请求体:123&#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;java elasticsearch&quot;&#125;&#125; es转换后的请求体:12345678&#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;term&quot;: &#123; &quot;title&quot;: &quot;java&quot; &#125;&#125;, &#123; &quot;term&quot;: &#123; &quot;title&quot;: &quot;elasticsearch&quot; &#125;&#125; ] &#125;&#125; 使用诸如上面的match query进行多值搜索的时候,es会在底层自动将这个match query转换为bool的语法 示例二原请求体:12345678&#123; &quot;match&quot;: &#123; &quot;title&quot;: &#123; &quot;query&quot;: &quot;java elasticsearch&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125;&#125; es转换后的请求体:12345678&#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;term&quot;: &#123; &quot;title&quot;: &quot;java&quot; &#125;&#125;, &#123; &quot;term&quot;: &#123; &quot;title&quot;: &quot;elasticsearch&quot; &#125;&#125; ] &#125;&#125; 示例三原请求体:12345678&#123; &quot;match&quot;: &#123; &quot;title&quot;: &#123; &quot;query&quot;: &quot;java elasticsearch hadoop spark&quot;, &quot;minimum_should_match&quot;: &quot;75%&quot; &#125; &#125;&#125; es转换后的请求体:1234567891011&#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;term&quot;: &#123; &quot;title&quot;: &quot;java&quot; &#125;&#125;, &#123; &quot;term&quot;: &#123; &quot;title&quot;: &quot;elasticsearch&quot; &#125;&#125;, &#123; &quot;term&quot;: &#123; &quot;title&quot;: &quot;hadoop&quot; &#125;&#125;, &#123; &quot;term&quot;: &#123; &quot;title&quot;: &quot;spark&quot; &#125;&#125; ], &quot;minimum_should_match&quot;: 3 &#125;&#125;]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-43-实战案例-手动控制全文检索结果的精准度]]></title>
    <url>%2F2018%2F12%2F04%2FElasticsearch-43-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B-%E6%89%8B%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E7%9A%84%E7%B2%BE%E5%87%86%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[准备工作为帖子增加标题字段1234567891011POST /forum/article/_bulk&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;title&quot; : &quot;this is java and elasticsearch blog&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;2&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;title&quot; : &quot;this is java blog&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;3&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;title&quot; : &quot;this is elasticsearch blog&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;4&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;title&quot; : &quot;this is java, elasticsearch, hadoop blog&quot;&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;5&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;title&quot; : &quot;this is spark blog&quot;&#125; &#125; 需求一搜索标题中包含java 或 elasticsearch的帖子12345678GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;java elasticsearch&quot; &#125; &#125;&#125; 就是只要标题中有java,elasticsearch其中的一个就可以作为返回结果,这个就和之前我们说的term query不一样了, term query是exact value,而这里的搜索是full text match query是负责全文检索的,当然如果要检索的field是not_analyzed不分词的,那么他的作用就和term query是一样的 需求二搜索标题中包含 java 和 elasticsearch的帖子1234567891011GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;:&#123; &quot;query&quot;: &quot;java elasticsearch&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125; &#125;&#125; 搜索结果精准度控制的第一步:灵活使用and关键字,如果希望所有的搜索关键字都要匹配,那么就用and,可以实现单纯match query无法实现的效果 需求三搜索包含java,elasticsearch,spark,hadoop,4个关键字中,至少3个的帖子12345678910111213141516GET forum/article/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;:&#123; &quot;query&quot;: &quot;java elasticsearch spark hadoop&quot;, &quot;minimum_should_match&quot;:&quot;75%&quot; &#125; &#125; &#125;&#125;``` 搜索结果精准度控制第二步:指定一些关键字中至少匹配到其中多少个关键字才能作为返回结果 #### bool组合搜索 GET forum/article/_search{ “query”: { “bool”: { “must”: [ { “match”: { “title”: “java” } } ], “must_not”: [ { “match”: { “title”: “spark” } } ], “should”: [ { “match”: { “title”: “hadoop” } }, { “match”: { “title”: “elasticsearch” } } ] } }}1234567891011121314151617看一下上面这个搜索请求, 就是搜索必须包含java,必须不包含spark,可以包含hadoop或elasticsearch的数据 #### bool组合多个搜索条件,计算relevance score的规则**must和should搜索对应的分数,加起来,除以must和should的总数** 在上面这个查询中: 排名第一:java,同时包含should中所有的关键字,hadoop,elasticsearch 排名第二:java,同时包含should中的elasticsearch 排名第三:java,不包含should中的任何关键字 should是会影响相关度分数的 must是确保说,谁必须有这个关键字,同时会根据这个must的条件去计算出document对这个搜索条件的relevance score 在满足must的基础之上,should中的条件,不匹配也可以,但是如果匹配的更多,那么document的relevance score就会更高 #### 用bool组合查询实现需求三搜索包含java,elasticsearch,spark,hadoop,4个关键字中,至少3个的帖子 GET /forum/article/_search{ “query”: { “bool”: { “should”: [ { “match”: { “title”: “java” } }, { “match”: { “title”: “elasticsearch” } }, { “match”: { “title”: “spark” } }, { “match”: { “title”: “hadoop” } } ], “minimum_number_should_match”: 3 } }}` 默认情况下should是可以不匹配任何一个的,但是如果没有must的话 should中必须匹配一个才可以,但是也可以通过我们上面请求用到的minimum_number_should_match 来控制必须满足几个才能作为返回结果 总结全文见检索的时候,进行多个值的检索,可以用match query 也可以空should搜过结果精准度控制: 用 and operator 或 minimum_number_should_match]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-42-实战案例-range filter进行范围过滤]]></title>
    <url>%2F2018%2F12%2F03%2FElasticsearch-42-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B-range-filter%E8%BF%9B%E8%A1%8C%E8%8C%83%E5%9B%B4%E8%BF%87%E6%BB%A4%2F</url>
    <content type="text"><![CDATA[准备工作为帖子增加浏览量的字段123456789POST /forum/article/_bulk&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;view_cnt&quot; : 30&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;2&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;view_cnt&quot; : 50&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;3&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;view_cnt&quot; : 100&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;4&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;view_cnt&quot; : 80&#125; &#125; 需求一搜索浏览量在30-60之间的帖子123456789101112131415GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;view_cnt&quot;: &#123; &quot;gt&quot;: 30, &quot;lt&quot;: 60 &#125; &#125; &#125; &#125; &#125;&#125; 返回值:1234567891011121314151617181920212223242526272829303132&#123; &quot;took&quot;: 2, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 50 &#125; &#125; ] &#125;&#125; lt: 小于 lte: 小于等于 gt: 大于 gte: 大于等于 需求二搜索发帖日期在最近1个月的帖子 先来添加一条最近一个月的帖子123POST /forum/article/_bulk&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 5 &#125;&#125;&#123; &quot;articleID&quot; : &quot;DHJK-B-1395-#Ky5&quot;, &quot;userID&quot; : 3, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2018-12-03&quot;, &quot;tag&quot;: [&quot;elasticsearch&quot;], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 10 &#125; 添加完成后搜索,一个月,也就是当前时间减去30天1234567891011121314GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;postDate&quot;: &#123; &quot;gt&quot;: &quot;now-30d&quot; &#125; &#125; &#125; &#125; &#125;&#125; 也可以是1234567891011121314GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;postDate&quot;: &#123; &quot;gt&quot;: &quot;2018-12-03||-30d&quot; &#125; &#125; &#125; &#125; &#125;&#125; 返回值:1234567891011121314151617181920212223242526272829303132&#123; &quot;took&quot;: 2, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;DHJK-B-1395-#Ky5&quot;, &quot;userID&quot;: 3, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2018-12-03&quot;, &quot;tag&quot;: [ &quot;elasticsearch&quot; ], &quot;tag_cnt&quot;: 1, &quot;view_cnt&quot;: 10 &#125; &#125; ] &#125;&#125; 总结 range 相当于sql中的between and 或者是 &gt;= , &lt;= range用来做范围过滤]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-41-实战案例-terms搜索多个值及搜索结果优化]]></title>
    <url>%2F2018%2F12%2F03%2FElasticsearch-41-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B-terms%E6%90%9C%E7%B4%A2%E5%A4%9A%E4%B8%AA%E5%80%BC%E5%8F%8A%E6%90%9C%E7%B4%A2%E7%BB%93%E6%9E%9C%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[之前的几个案例中都是用的term用来搜索. 本文使用terms来搜索数据 terms,就相当于sql中的in 准备工作为帖子添加tag字段123456789POST /forum/article/_bulk&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;tag&quot; : [&quot;java&quot;, &quot;hadoop&quot;]&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;2&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;tag&quot; : [&quot;java&quot;]&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;3&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;tag&quot; : [&quot;hadoop&quot;]&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;4&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;tag&quot; : [&quot;java&quot;, &quot;elasticsearch&quot;]&#125; &#125; terms搜索需求一搜索articleID为KDKE-B-9947-#kL5或QQPX-R-3956-#aD8的帖子 将需求转为sql就是:123SELECT * FROM forum.article whereid in (&apos;KDKE-B-9947-#kL5&apos;,&apos;QQPX-R-3956-#aD8&apos;) 然后在es中去构建搜索条件123456789101112131415GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;terms&quot;: &#123; &quot;articleID&quot;: [ &quot;KDKE-B-9947-#kL5&quot;, &quot;QQPX-R-3956-#aD8&quot; ] &#125; &#125; &#125; &#125;&#125; 需求二搜索tag中包含java的帖子1234567891011121314GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;terms&quot;: &#123; &quot;tag&quot;: [ &quot;java&quot; ] &#125; &#125; &#125; &#125;&#125; 返回值:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&#123; &quot;took&quot;: 3, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;QQPX-R-3956-#aD8&quot;, &quot;userID&quot;: 2, &quot;hidden&quot;: true, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;elasticsearch&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot;, &quot;tag&quot;: [ &quot;java&quot;, &quot;hadoop&quot; ] &#125; &#125; ] &#125;&#125; 从结果上看的话,tag的值中只要包含了java就被搜索出来了 优化搜索结果上面一个搜索中只要包含了java的数据都被搜索出来了,现在我们想搜索只包含java的数据 首先,我们需要修改一下数据,增加一个tag_cnt的字段123456789POST /forum/article/_bulk&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;tag_cnt&quot; : 2&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;2&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;tag_cnt&quot; : 1&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;3&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;tag_cnt&quot; : 1&#125; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;4&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;tag_cnt&quot; : 2&#125; &#125; 执行完毕后,再次来构建搜索条件1234567891011121314151617181920212223GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;:[ &#123; &quot;term&quot;:&#123; &quot;tag_cnt&quot;:1 &#125; &#125;, &#123; &quot;terms&quot;:&#123; &quot;tag&quot;:[&quot;java&quot;] &#125; &#125; ] &#125; &#125; &#125; &#125;&#125; 返回值:12345678910111213141516171819202122232425262728293031&#123; &quot;took&quot;: 4, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot;, &quot;tag&quot;: [ &quot;java&quot; ], &quot;tag_cnt&quot;: 1 &#125; &#125; ] &#125;&#125; 总结 掌握terms多值搜索 优化terms多值搜索结果 terms相当于sql中的in]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-40-实战案例-组合多个filter搜索]]></title>
    <url>%2F2018%2F12%2F03%2FElasticsearch-40-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B-%E7%BB%84%E5%90%88%E5%A4%9A%E4%B8%AAfilter%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[之前我们有写过用bool来组合多个query,同样的bool也可以组合多个filter来搜索 基于bool组合多个filter搜索数据需求一搜索发帖日期为2017-01-01,或者帖子ID为XHDK-A-1293-#fJ3的帖子,同时要求帖子的发帖日期绝对不为2017-01-02 这个需求如果写为SQL的话就是:1234SELECT * FROM forum.article where(postDate=&apos;2017-01-01&apos; or id =&apos;XHDK-A-1293-#fJ3&apos;)and postDate &lt;&gt; 2017-01-02 然后我们在es中组合一下搜索条件123456789101112131415161718192021222324GET forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;:[ &#123; &quot;term&quot;:&#123;&quot;postDate&quot;:&quot;2017-01-01&quot;&#125; &#125;, &#123; &quot;term&quot;:&#123;&quot;articleID&quot;:&quot;XHDK-A-1293-#fJ3&quot;&#125; &#125; ], &quot;must_not&quot;:[ &#123; &quot;term&quot;:&#123;&quot;postDate&quot;:&quot;2017-01-02&quot;&#125; &#125; ] &#125; &#125; &#125; &#125;&#125; 返回数据:123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;took&quot;: 61, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 2, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;JODL-X-1937-#pV7&quot;, &quot;userID&quot;: 2, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot; &#125; &#125; ] &#125;&#125; 需求二搜索帖子ID为XHDK-A-1293-#fJ3,或者是帖子ID为JODL-X-1937-#pV7而且发帖日期为2017-01-01的帖子 先来将需求转化为sql12345SELECT * FROM forum.article whereid = &apos;XHDK-A-1293-#fJ3&apos;or(id=&apos;JODL-X-1937-#pV7&apos; and postDate = &apos;2017-01-01&apos;) 然后在es中组合搜索条件 12345678910111213141516171819202122232425262728293031323334GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;:[ &#123; &quot;term&quot;:&#123; &quot;articleID&quot;:&quot;XHDK-A-1293-#fJ3&quot; &#125; &#125;, &#123; &quot;bool&quot;:&#123; &quot;must&quot;:[ &#123; &quot;term&quot;:&#123; &quot;articleID&quot;:&quot;JODL-X-1937-#pV7&quot; &#125; &#125;, &#123; &quot;term&quot;:&#123; &quot;postDate&quot;:&quot;2017-01-01&quot; &#125; &#125; ] &#125; &#125; ] &#125; &#125; &#125; &#125;&#125; 返回值:123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;took&quot;: 8, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 2, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;JODL-X-1937-#pV7&quot;, &quot;userID&quot;: 2, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot; &#125; &#125; ] &#125;&#125; 总结 should: 可以匹配其中任意一个 must: 必须匹配 must_not: 必须不匹配]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-39-filter原理深度剖析]]></title>
    <url>%2F2018%2F11%2F30%2FElasticsearch-39-filter%E5%8E%9F%E7%90%86%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[filter执行原理场景举个例子,假设有个字段是date类型的,在倒排索引中: word document1 document2 document3 2017-01-01 √ √ 2017-02-02 √ √ 2017-03-03 √ √ √ 在倒排索引中查找搜索串,获取document list这时候一个filter查询:2017-02-02,在倒排索引里面找,对应的document list是doc2,doc3 为每个在倒排索引中搜索到的结果构建一个bitset这点非常重要, 使用找到的document list构建一个bitset,一个二进制数组,数组每个元素都是0或1,用来标识一个doc对一个filter条件是否匹配,如果匹配就是1,不匹配就是0.上面的例子中,构建的bitset就是[0,1,1] 尽可能用简单的数据结构去实现复杂的功能,可以节省内存空间,提升性能 遍历每个过滤条件对应的bitset,优先从最稀疏的开始搜索,查找满足条件的所有document在一个search请求中,可以发出多个filter条件(这个后面再具体说),每个filter会对应一个bitset遍历每个filter条件对应的bitset,先从最稀疏的开始遍历. 怎么算稀疏呢?[0,0,0,1,0,0] – 比较稀疏[0,1,0,1,0,1]先遍历比较稀疏的bitset,可以过滤掉尽可能多的数据 比如现在有个请求 filter: postDate=2017-01,userID=1,然后构建的两个bitset分别是:[0,0,1,==1==,0,0][0,1,0,==1==,0,1]遍历玩两个bitset之后,找到匹配所有条件的document,就是第4个,这个时候就可以将符合结果document返回给客户端了 caching bitset 跟踪query对于在最近的256个query中超过一定次数的过滤条件,缓存其bitset.对于小segment(&lt;1000或&lt;3%)不缓存 举个例子,在最近的256次查询中,postDate=2017-02-02这个条件出现超过了一定的次数(不固定), 就会自动缓存这个filter对应的bitset filter对于小的segment中获取到的结果可以不缓存, segment中记录数小于1000的和segment大小小于index总大小的3%的 因为segment数据量很小的时候,扫描是很快的,而且我们之前有说过,segment会在后台自动合并的,小的segment很快会和其他小的segment合并,此时缓存也就没有什么意义了 大部分情况下 filter会在query之前执行filter先执行可以先过滤掉一部分数据,之前说过query是会计算相关度分数,然后去排序的,而filter是不计算分数,也不排序,所以先执行filter过滤掉尽可能多的数据 如果document有新增或修改,那么cached bitset会被自动更新举个例子,之前有个filter 过滤条件是postDate=2017-02-02,然后他的bitset是[0,0,0,1]这个时候如果新增了一条document进来 postDate也是 2017-02-02,id是5, 那么这个bitset会自动更新为[0,0,0,1,1]同理,如果id = 1的document的postDate更新为2017-02-02 那么bitset也会更新为[1,0,0,1,1] 以后只要是有相同的filter条件的，会直接来使用这个过滤条件对应的cached bitset]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-38-实战案例-term filter搜索]]></title>
    <url>%2F2018%2F11%2F30%2FElasticsearch-38-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B-term-filter%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[之前都是随便写的一些demo来测试es的api,本文及以后将会基于一个案例,来更加深入使用这些api,之后会再使用Java api来实现具体功能. 场景以一个IT论坛为背景,来置顶搜索需求,以及实现. 测试数据123456789POST /forum/article/_bulk&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 1 &#125;&#125;&#123; &quot;articleID&quot; : &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot; : 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 2 &#125;&#125;&#123; &quot;articleID&quot; : &quot;KDKE-B-9947-#kL5&quot;, &quot;userID&quot; : 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-02&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 3 &#125;&#125;&#123; &quot;articleID&quot; : &quot;JODL-X-1937-#pV7&quot;, &quot;userID&quot; : 2, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 4 &#125;&#125;&#123; &quot;articleID&quot; : &quot;QQPX-R-3956-#aD8&quot;, &quot;userID&quot; : 2, &quot;hidden&quot;: true, &quot;postDate&quot;: &quot;2017-01-02&quot; &#125; 使用_bulk api来添加数据,目前我们只添加这几个field,articleID,userId,hidden 执行完毕以后,我们来查看一下dynamic mapping给我建立的mapping1GET /forum/_mapping/article 返回值:12345678910111213141516171819202122232425262728&#123; &quot;forum&quot;: &#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;articleID&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; // 1 &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125;, &quot;hidden&quot;: &#123; &quot;type&quot;: &quot;boolean&quot; &#125;, &quot;postDate&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;userID&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125; &#125; &#125; &#125; &#125;&#125; 这里我们看1处,”articleID”的类型是text,里面还有一个”articleID.keyword”,这个东西是干嘛的呢? 在新版es中,type=text的时候,默认会设置两个field,一个是field本身,比如”articleID”,他是分词的,还有一个就是field.keyword,比如”articleID.keyword”,默认是不分词的, keyword里面还有一个属性是”ignore_above”:256,意思就是最多会保留256个字符 term filter的使用term filter/query: 对搜索文本不分词,直接拿去倒排索引中去匹配,你输入的是什么,就去匹配什么 需求1:根据用户id来搜索帖子123456789101112GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;term&quot;: &#123; &quot;userID&quot;: 1 &#125; &#125; &#125; &#125;&#125; 需求2:搜索没有隐藏的帖子123456789101112GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;term&quot;: &#123; &quot;hidden&quot;: false &#125; &#125; &#125; &#125;&#125; 需求3:根据发帖日期搜索帖子123456789101112GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;term&quot;: &#123; &quot;postDate&quot;: &quot;2017-01-01&quot; &#125; &#125; &#125; &#125;&#125; 需求4:根据帖子id搜索帖子123456789101112GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;term&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot; &#125; &#125; &#125; &#125;&#125; 返回值:1234567891011121314&#123; &quot;took&quot;: 5, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 0, &quot;max_score&quot;: null, &quot;hits&quot;: [] &#125;&#125; 这里可以看到,一条结果也没有,但是应该是有这个数据的,为什么呢? 在添加数据的时候,字符串是默认会去分词,然后建立倒排索引的,而term是不去分词的,所以是查不到的 我们可以用上面es自动建立的keyword来进行搜索123456789101112GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;term&quot;: &#123; &quot;articleID.keyword&quot;: &quot;XHDK-A-1293-#fJ3&quot; &#125; &#125; &#125; &#125;&#125; 返回值:123456789101112131415161718192021222324252627&#123; &quot;took&quot;: 2, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot; &#125; &#125; ] &#125;&#125; 这样就可以搜索到了,但是同时也有一个问题,就是keyword只会保留256个字符,如果这个字段太长的话那就还是搜索不到的.这时候,我们最好重建索引,手动设置mapping 删除索引1DELETE /forum 手动创建索引,指定articleID不分词123456789101112PUT /forum&#123; &quot;mappings&quot;: &#123; &quot;article&quot;:&#123; &quot;properties&quot;: &#123; &quot;articleID&quot;:&#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125; &#125;&#125; 然后把上面的数据重新添加进去.现在,再用articleID来进行查询123456789101112GET /forum/article/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;term&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot; &#125; &#125; &#125; &#125;&#125; 返回值:123456789101112131415161718192021222324252627&#123; &quot;took&quot;: 2, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;forum&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;articleID&quot;: &quot;XHDK-A-1293-#fJ3&quot;, &quot;userID&quot;: 1, &quot;hidden&quot;: false, &quot;postDate&quot;: &quot;2017-01-01&quot; &#125; &#125; ] &#125;&#125; 这时候就可以查询的到了 总结 term filter:根据exact value来进行搜索,数字,Boolean,date类型的天然支持 text类型的field需要在建立的索引的时候指定not_analyzed(新版中可以直接指定type为keyword),才可以使用term]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-37-Java API document 增删改查]]></title>
    <url>%2F2018%2F11%2F29%2FElasticsearch-37-Java-API-document-%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[前文都是讲的理论知识,用restful API来做的测试. 本文将使用java API来操作索引,document. 添加依赖123456789101112&lt;!-- es依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;$&#123;elasticsearch.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;$&#123;elasticsearch.version&#125;&lt;/version&gt;&lt;/dependency&gt; yml配置1234567elasticsearch: ip: 127.0.0.1 port: 9300 pool: 5# 集群名称 cluster: name: elasticsearch 配置client12345678910111213141516171819202122232425262728293031323334353637383940414243@Configuration@Slf4jpublic class ElasticsearchConfig &#123; /** * ip地址 */ @Value(&quot;$&#123;elasticsearch.ip&#125;&quot;) private String hostName; @Value(&quot;$&#123;elasticsearch.port&#125;&quot;) private int port; @Value(&quot;$&#123;elasticsearch.pool&#125;&quot;) private int poolSize; @Value(&quot;$&#123;elasticsearch.cluster.name&#125;&quot;) private String clusterName; @Bean public TransportClient init()&#123; TransportClient transportClient = null; try &#123; // 配置 Settings settings = Settings.builder() .put(&quot;cluster.name&quot;, clusterName) // 集群嗅探机制,找到es集群 .put(&quot;client.transport.sniff&quot;, true) // 增加线程池个数 .put(&quot;thread_pool.search.size&quot;, poolSize) .build(); transportClient = new PreBuiltTransportClient(settings) // 设置地址端口号 .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(hostName), port)); &#125; catch (Exception e)&#123; log.error(&quot;elasticsearch TransportClient init error,&#123;&#125;&quot;, e); &#125; return transportClient; &#125;&#125; 基础的配置已经完成了,接下来就是具体的方法 增删改查节点和索引Util工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471@Component@Slf4jpublic class ElasticsearchUtils &#123; @Autowired private TransportClient transportClient; private static TransportClient client; @PostConstruct public void init()&#123; client = this.transportClient; &#125; /** * 判断索引是否存在 * @param indexName 索引名称 * @return true/false */ public static boolean indexExist(String indexName)&#123; IndicesExistsResponse indicesExistsResponse = client.admin() .indices() .exists(new IndicesExistsRequest(indexName)) .actionGet(); if (indicesExistsResponse.isExists())&#123; log.info(&quot;Index [&apos;&#123;&#125;&apos;] is exists&quot;, indexName); &#125; else &#123; log.info(&quot;Index [&apos;&#123;&#125;&apos;] is not exists&quot;, indexName); &#125; return indicesExistsResponse.isExists(); &#125; /** * 创建索引 * @param indexName 索引名称 * @return isAcknowledged */ public static boolean createIndex(String indexName)&#123; if (!indexExist(indexName))&#123; log.info(&quot;Index is not exist&quot;); &#125; CreateIndexResponse response = client.admin() .indices() .prepareCreate(indexName) .execute() .actionGet(); return response.isAcknowledged(); &#125; /** * 删除索引 * @param indexName 索引名称 * @return isAcknowledged */ public static boolean deleteIndex(String indexName)&#123; if (!indexExist(indexName))&#123; log.info(&quot;Index is not exist&quot;); &#125; DeleteIndexResponse response = client.admin() .indices() .prepareDelete(indexName) .execute() .actionGet(); return response.isAcknowledged(); &#125; /** * 创建一个document,需要手动指定id * @param indexName 索引名称 * @param typeName 类型名称 * @param id id * @param xContentBuilder 数据(fields) * @return id */ public static String createDocument(String indexName, String typeName, String id, XContentBuilder xContentBuilder)&#123; IndexResponse response = client .prepareIndex(indexName, typeName, id) .setSource(xContentBuilder) .get(); log.info(&quot;add document response:&#123;&#125;&quot;, response.toString()); return response.getId(); &#125; /** * 创建一个document,不需要手动指定id * @param indexName 索引名称 * @param typeName 类型名称 * @param xContentBuilder 数据(fields) * @return id */ public static String createDocumentWithNoId(String indexName, String typeName, XContentBuilder xContentBuilder)&#123; IndexResponse response = client .prepareIndex(indexName, typeName) .setSource(xContentBuilder) .get(); log.info(&quot;add document response:&#123;&#125;&quot;, response.toString()); return response.getId(); &#125; /** * 更新document,partial update * @param indexName 索引名称 * @param typeName 类型名称 * @param id id * @param xContentBuilder 数据 * @return id */ public static String updateDocument(String indexName, String typeName, String id, XContentBuilder xContentBuilder)&#123; UpdateResponse updateResponse = client .prepareUpdate(indexName, typeName, id) .setDoc(xContentBuilder) .get(); log.info(&quot;update response:&#123;&#125;&quot;, updateResponse.toString()); return updateResponse.getId(); &#125; /** * 删除document * @param indexName 索引名称 * @param typeName 类型名称 * @param id id * @return id */ public static String deleteDocument(String indexName, String typeName, String id)&#123; DeleteResponse response = client .prepareDelete(indexName, typeName, id) .get(); log.info(&quot;delete response:&#123;&#125;&quot;, response.toString()); return response.getId(); &#125; /** * 根据id获取document * @param indexName 索引名称 * @param typeName 类型名称 * @param id id * @return _source数据 */ public static String getDocumentById(String indexName, String typeName, String id)&#123; GetResponse response = client .prepareGet(indexName, typeName, id) .get(); log.info(&quot;get response&quot;); return response.getSourceAsString(); &#125; /** * 只做查询,没有排序 * @param indexes 索引 * @param types 类型 * @param matchMap 搜索条件 * @param fields 要显示的fields,不传返回全部 * @return 结果集 */ public static List&lt;Map&lt;String,Object&gt;&gt; searchDocument(String indexes, String types, Map&lt;String,String&gt; matchMap, String fields)&#123; return searchDocument(indexes, types, 0, 0, matchMap, false, null, fields, null, null, null); &#125; /** * 查询/精准匹配,可以排序 * @param indexes 索引 * @param types 类型 * @param matchMap 查询条件 * @param fields 要显示的fields,不传返回全部 * @param matchPhrase true 使用短语精准匹配 * @param sortField 排序field * @param sortOrder 正序倒序(正序的话需要字段有正排索引) * @return 结果集 */ public static List&lt;Map&lt;String,Object&gt;&gt; searchDocument(String indexes, String types, Map&lt;String,String&gt; matchMap, String fields, boolean matchPhrase, String sortField, SortOrder sortOrder)&#123; return searchDocument(indexes, types, 0, 0, matchMap, matchPhrase, null, fields, sortField, sortOrder, null); &#125; /** * 查询/精准匹配,可以排序,高亮,文档大小限制 * @param indexes 索引 * @param types 类型 * @param matchMap 查询条件 * @param fields 要显示的fields,不传返回全部 * @param matchPhrase true 使用短语精准匹配 * @param sortField 排序field * @param sortOrder 正序倒序(正序的话需要字段有正排索引) * @param highlightField 高亮字段 * @param size 文档大小限制 * @return 结果集 */ public static List&lt;Map&lt;String,Object&gt;&gt; searchDocument(String indexes, String types, Map&lt;String,String&gt; matchMap, String fields, boolean matchPhrase, String sortField, SortOrder sortOrder, String highlightField, Integer size)&#123; return searchDocument(indexes, types, 0, 0, matchMap, matchPhrase, highlightField, fields, sortField, sortOrder, size); &#125; /** * 搜索document * @param indexes 索引名 * @param types 类型 * @param startTime 开始时间 * @param endTime 结束时间 * @param matchMap 查询条件(filed:value) * @param matchPhrase true 使用短语精准匹配 * @param highlightField 高亮显示的field * @param fields 要显示的fields,不传返回全部 * @param sortField 排序field * @param sortOrder 正序倒序(正序的话需要字段有正排索引) * @param size 文档大小限制 * @return 结果集 */ public static List&lt;Map&lt;String, Object&gt;&gt; searchDocument(String indexes, String types, long startTime, long endTime, Map&lt;String,String&gt; matchMap, boolean matchPhrase, String highlightField, String fields, String sortField, SortOrder sortOrder, Integer size)&#123; if (StringUtils.isEmpty(indexes))&#123; return null; &#125; // 构建查询的request body SearchRequestBuilder searchRequestBuilder = client.prepareSearch(indexes.split(&quot;,&quot;)); // 拆分type if (StringUtils.isNotEmpty(types))&#123; searchRequestBuilder.setTypes(types.split(&quot;,&quot;)); &#125; // 组合查询 bool BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); // 组装查询条件 boolQueryBuilder = boolQuery(boolQueryBuilder, startTime, endTime, matchMap, matchPhrase); // 设置高亮字段 searchRequestBuilder = setHighlightField(searchRequestBuilder, highlightField); // 搜索条件加到request中 searchRequestBuilder.setQuery(boolQueryBuilder); // 定制返回的fields if (StringUtils.isNotEmpty(fields))&#123; searchRequestBuilder.setFetchSource(fields.split(&quot;,&quot;), null); &#125; searchRequestBuilder.setFetchSource(true); // 设置排序 if (StringUtils.isNotEmpty(sortField))&#123; searchRequestBuilder.addSort(sortField, sortOrder); &#125; // 设置文档大小限制 if (size != null &amp;&amp; size &gt; 0)&#123; searchRequestBuilder.setSize(size); &#125; // 把请求体打印出来 log.info(&quot;查询请求体:&#123;&#125;&quot;, searchRequestBuilder); // 发送请求,执行查询 SearchResponse response = searchRequestBuilder .execute() .actionGet(); long totalHits = response.getHits().totalHits(); long length = response.getHits().getHits().length; log.info(&quot;共查询到[&#123;&#125;]条数据,处理数据条数[&#123;&#125;]&quot;, totalHits, length); if (response.status().getStatus() == 200)&#123; return setSearchResponse(response, highlightField); &#125; return null; &#125; /** * 分页查询 * @param indexes 索引 * @param types 类型 * @param pageNum 页码 * @param pageSize 每页显示数量 * @param startTime 开始时间 * @param endTime 结束时间 * @param fields 要显示的字段 * @param sortField 排序字段 * @param sortOrder 正序倒序(正序需要排序的字段有正排索引) * @param matchPhrase true 精准匹配 * @param highlightField 高亮子弹 * @param matchMap 查询条件 * @return PageVO */ public static PageVO searchDocumentPage(String indexes, String types, int pageNum, int pageSize, long startTime, long endTime, String fields, String sortField, SortOrder sortOrder, boolean matchPhrase, String highlightField, Map&lt;String,String&gt; matchMap)&#123; if (StringUtils.isEmpty(indexes))&#123; return null; &#125; SearchRequestBuilder searchRequestBuilder = client.prepareSearch(indexes.split(&quot;,&quot;)); if (StringUtils.isNotEmpty(types))&#123; searchRequestBuilder.setTypes(types.split(&quot;,&quot;)); &#125; searchRequestBuilder.setSearchType(SearchType.QUERY_THEN_FETCH); // 设置需要显示的字段 if (StringUtils.isNotEmpty(fields))&#123; searchRequestBuilder.setFetchSource(fields.split(&quot;,&quot;), null); &#125; // 设置排序字段 if (StringUtils.isNotEmpty(sortField))&#123; searchRequestBuilder.addSort(sortField, sortOrder); &#125; // 组合查询 bool BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); // 组装查询条件 boolQueryBuilder = boolQuery(boolQueryBuilder, startTime, endTime, matchMap, matchPhrase); // 设置高亮字段 searchRequestBuilder = setHighlightField(searchRequestBuilder, highlightField); // 搜索条件加到request中 searchRequestBuilder.setQuery(boolQueryBuilder); searchRequestBuilder.setQuery(QueryBuilders.matchAllQuery()); // 设置分页 searchRequestBuilder.setFrom(pageNum).setSize(pageSize); // 设置按照匹配度排序 searchRequestBuilder.setExplain(true); // 打印请求体 log.info(&quot;请求体:&#123;&#125;&quot;, searchRequestBuilder); // 发送请求,执行查询 SearchResponse response = searchRequestBuilder .execute() .actionGet(); long totalHits = response.getHits().totalHits(); long length = response.getHits().getHits().length; log.info(&quot;共查询到[&#123;&#125;]条数据,处理数据条数[&#123;&#125;]&quot;, totalHits, length); if (response.status().getStatus() == 200)&#123; // 解析查询对象 List&lt;Map&lt;String,Object&gt;&gt; rList = setSearchResponse(response, highlightField); return new PageVO(pageNum, pageSize, (int) totalHits, rList); &#125; return null; &#125; /** * 高亮结果集 特殊处理 * @param searchResponse 查询返回结果 * @param highlightField 高亮字段 * @return 结果 */ public static List&lt;Map&lt;String,Object&gt;&gt; setSearchResponse(SearchResponse searchResponse, String highlightField)&#123; List&lt;Map&lt;String,Object&gt;&gt; sourceList = new ArrayList&lt;&gt;(); StringBuilder stringBuilder = new StringBuilder(); // 循环查询结果 for (SearchHit searchHitFields : searchResponse.getHits().getHits()) &#123; // 把id放到_source里面去 searchHitFields.getSource().put(&quot;id&quot;, searchHitFields.getId()); // 有高亮字段的话做处理 if (StringUtils.isNotEmpty(highlightField))&#123; log.info(&quot;遍历高亮结果集,覆盖正常结果集...&#123;&#125;&quot;, searchHitFields.getSource()); Text[] texts = searchHitFields.getHighlightFields().get(highlightField).getFragments(); if (texts != null)&#123; for (Text text : texts) &#123; stringBuilder.append(text.toString()); &#125; // 遍历高亮结果集,覆盖正常结果集 searchHitFields.getSource().put(highlightField, stringBuilder.toString()); &#125; &#125; sourceList.add(searchHitFields.getSource()); &#125; return sourceList; &#125; /** * 封装 * @param boolQueryBuilder boolQueryBuilder * @param startTime 开始时间 * @param endTime 结束时间 * @param matchMap 查询条件 * @param matchPhrase true 使用精准匹配 * @return boolQueryBuilder */ public static BoolQueryBuilder boolQuery(BoolQueryBuilder boolQueryBuilder, long startTime, long endTime, Map&lt;String, String&gt; matchMap, boolean matchPhrase)&#123; // TODO 不清楚是做什么 if (startTime &gt; 0 &amp;&amp; endTime &gt; 0)&#123; boolQueryBuilder.must(QueryBuilders.rangeQuery(&quot;processTime&quot;) .format(&quot;epoch_millis&quot;) .from(startTime) .to(endTime) .includeLower(true) .includeUpper(true) ); &#125; // 搜索条件 if (!matchMap.isEmpty())&#123; for (Map.Entry&lt;String,String&gt; entry : matchMap.entrySet()) &#123; if (StringUtils.isNoneBlank(entry.getKey(),entry.getValue()))&#123; if (matchPhrase == Boolean.TRUE)&#123; // 精准匹配 boolQueryBuilder.must(QueryBuilders.matchPhraseQuery(entry.getKey(), entry.getValue())); &#125; else &#123; boolQueryBuilder.must(QueryBuilders.matchQuery(entry.getKey(), entry.getValue())); &#125; &#125; &#125; &#125; return boolQueryBuilder; &#125; /** * 封装设置高亮字段 * @param searchRequestBuilder searchRequestBuilder * @param highlightField 高亮字段 * @return searchRequestBuilder */ public static SearchRequestBuilder setHighlightField(SearchRequestBuilder searchRequestBuilder, String highlightField)&#123; // 高亮字段 if (StringUtils.isNotEmpty(highlightField))&#123; HighlightBuilder highlightBuilder = new HighlightBuilder(); // 设置前缀// highlightBuilder.preTags(&quot;&lt;span style=&apos;color:red&apos;&gt;&quot;); // 设置后缀// highlightBuilder.postTags(&quot;&lt;/span&gt;&quot;); // 设置高亮字段 highlightBuilder.field(highlightField); searchRequestBuilder.highlighter(highlightBuilder); &#125; return searchRequestBuilder; &#125;&#125; 分页model12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/** * @author 周泽 * @date Create in 10:38 2018/11/29 * @Description 分页结果集 */@Getter@Setterpublic class PageVO &#123; /** * 当前页码 */ private Integer pageNum; /** * 一页显示数量 */ private Integer pageSize; /** * 总数量 */ private Integer total; /** * 结果集合 */ private List&lt;Map&lt;String,Object&gt;&gt; rList; /** * 共有多少页 */ private Integer pageCount; /** * 页码列表的开始索引(包含) */ private Integer beginPageIndex; /** * 码列表的结束索引(包含) */ private Integer endPageIndex; /** * 只接受前4个必要的属性，会自动的计算出其他3个属性的值 * @param pageNum 当前页码 * @param pageSize 每页显示条数 * @param total 总条数 * @param rList 结果集合 */ public PageVO(int pageNum, int pageSize, int total, List&lt;Map&lt;String, Object&gt;&gt; rList) &#123; this.pageNum = pageNum; this.pageSize = pageSize; this.total = total; this.rList = rList; // 计算总页码 pageCount = (total + pageSize - 1) / pageSize; // 计算 beginPageIndex 和 endPageIndex // &gt;&gt; 总页数不多于10页，则全部显示 if (pageCount &lt;= 10) &#123; beginPageIndex = 1; endPageIndex = pageCount; &#125; else &#123; // &gt;&gt; 总页数多于10页，则显示当前页附近的共10个页码 // 当前页附近的共10个页码（前4个 + 当前页 + 后5个） beginPageIndex = pageNum - 4; endPageIndex = pageNum + 5; // 当前面的页码不足4个时，则显示前10个页码 if (beginPageIndex &lt; 1) &#123; beginPageIndex = 1; endPageIndex = 10; &#125; // 当后面的页码不足5个时，则显示后10个页码 if (endPageIndex &gt; pageCount) &#123; endPageIndex = pageCount; beginPageIndex = pageCount - 10 + 1; &#125; &#125; &#125;&#125; 单元测试代码在源码里.源码地址]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-36-深度解析document增删改原理及优化过程]]></title>
    <url>%2F2018%2F11%2F27%2FElasticsearch-36-%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90document%E5%A2%9E%E5%88%A0%E6%94%B9%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[document写入原理在es底层,用的是Lucene,Lucene底层的index是分为多个segment的,每个segment都会存放部分数据 图中,客户端写入一个document的时候: 先写到了操作系统中的buffer缓存中 然后进行commit point buffer中的数据写入了新的index segment 然后写入操作系统的缓存中 缓存中的index segment被fsync强制刷新到磁盘上 同时新的index segment被打开,供搜索使用 将buffer缓存清空 更新删除原理如果是更新操作,实际上是将现有的document标记为deleted,然后将新的document写入新的index segment中,下次search过来的时候,也许会匹配到一个document的多个版本,但是之前的版本已经被标记为deleted了,所以会被过滤掉,不会作为搜索结果返回,删除操作同理. 每次commit point时,会有一个.del文件,标记了哪些segment中的哪些document被标记为deleted了搜索的时候回依次查询所有的segment,从旧的到新的,比如被修改过的document,在旧的segment中,会被标记为deleted,在新的segment中会有其新的数据 问题如果按照上面的流程的话,每次都必须等待fsync将segment刷入磁盘,才能将segment打开供search使用,这样的话,从一个document写入,到它可以被搜索,可能会超过1分钟,这就不是近实时的搜索了, 主要瓶颈在于fsync实际发生磁盘IO写数据进磁盘是很耗时的. 流程改进 数据写入buffer中 每隔一定的时间(默认是1s),buffer中的数据被写入新的segment文件,然后写入os cache中 只要segment写入到了os cache中了,那就直接打开index segment 供使用,不立即commit. 最后把buffer清空 数据写入os cache并被打开供搜索的过程,叫做refresh,默认是每隔1s refresh一次,就是说每隔一秒,就会将buffer中的数据写入一个新的index segment文件,先写入os cache中.所以es是近实时的,数据写入到可以搜索,默认是1秒. 我们也可以手动去设置refresh的间隔时间,比如时效性要求较低,写入数据一分钟后被搜索到就可以了123456PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;refresh_interval&quot;: &quot;60s&quot; &#125;&#125; 问题数据不及时写入到磁盘中,而是在缓存中,如果宕机的话,数据就会丢失,就不可靠了 再次优化写入流程 写入document的时候,数据同时写入buffer缓冲和translog日志文件 每隔1秒中,buffer中的数据被写入新的segment file,并进入os cache中,此时segment被打开并供search使用 buffer被清空 重复1-3,新的segment不断添加,buffer不断被清空,而translog中的数据不断累加 当translog长度达到一定的程度的时候,commit操作发生.5.1. buffer中所有数据写入一个新的segment中,并写入os cache 打开供使用.5.2. buffer被清空5.3. 一个commit point被写入磁盘,标明了所有的index segment5.4. os cache中的所有 数据被fsync强行刷到磁盘上去5.5. 现有的translog被清空,创建一个新的translog 基于translog和commit point进行数据恢复磁盘上存储的是上次commit point为止,所有的segment file,那么translog中存储的就是上一次flush(commit point)知道现在最近的数据变更记录如果说 os cache中已经囤积了一些数据,没有被刷到磁盘上,这个时候宕机了, 这时候机器重启,此时会将translog文件中的变更记录进行回放,重新执行之前的各种操作,等待下次commit即可 每次flush 会自动清空translog,默认每隔30分钟flush一次,或者当translog过大的时候,也会flush.我们也可以手动flush,POST /my_index/_flush,一般来说别手动flush,让它自动执行就可以了 translog,也是先放在缓存中的,每隔5秒被fsync一次到磁盘上.一般是在一次增删改操作之后. 如果说在一次增删改操作的时候正好要fsync translog到磁盘上,那么会等待primary shard和replica shard都成功之后,这次增删改操作才会成功 但是这种在一次增删改时强行fsync translog可能会导致部分操作比较耗时如果可以允许部分数据丢失,可以设置异步fsync translog 12345PUT /my_index/_settings&#123; &quot;index.translog.durability&quot;: &quot;async&quot;, &quot;index.translog.sync_interval&quot;: &quot;5s&quot;&#125; 终极优化上面说的,每秒生成一个segment文件,文件会越来越多,而且每次search都要搜索所有的segment,很耗时es会默认在后台执行合并的操作,在merge的时候,被标记为deleted的document 也会被彻底物理删除 每次merge的流程是 选择一些有相似大小的segment,merge成一个大的segment 将新的segment flush到磁盘上去 写一个新的commit point,包括了新的segment,并排除旧的那些segment 将新的segment打开供搜索 将旧的segment删除 也可以通过 POST /my_index/_optimize?max_num_segments=1 来手动合并,但是尽量不要手动执行]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-35-使用scroll+bulk+索引别名实现零停机重建索引]]></title>
    <url>%2F2018%2F11%2F27%2FElasticsearch-35-%E4%BD%BF%E7%94%A8scroll-bulk-%E7%B4%A2%E5%BC%95%E5%88%AB%E5%90%8D%E5%AE%9E%E7%8E%B0%E9%9B%B6%E5%81%9C%E6%9C%BA%E9%87%8D%E5%BB%BA%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[场景如果我们一开始新建了一个索引,并且依靠dynamic mapping,这个时候插入一条数据是2018-01-01这种格式的,这field就会被自动映射成了date类型,但是其实他应该是个string类型的,这时候应该怎么做呢? 解决方案一个field的设置是不能被修改的,如果要修改一个field,那么应该重新按照新的mapping来创建一个index,然后将旧的index中的数据查询出来,用_bulk api批量插入到新的索引中去 批量查询的时候,建议采用scroll api,采用多线程并发的方式来reindex数据. 案例我们先插入一条数据如下: 1234PUT /old_my_index/my_type/1&#123; &quot;title&quot;:&quot;2017-01-01&quot;&#125; 然后获取这个index的mapping 12345678910111213&#123; &quot;old_my_index&quot;: &#123; &quot;mappings&quot;: &#123; &quot;my_type&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125; &#125; &#125; &#125; &#125;&#125; 可以看到title已经被映射成了date类型,这时 如果我们在添加一个字符串的值是添加不进去的. 而且如果想修改这个field的类型也是不可能的 此时唯一的办法就是进行reindex,也就是说重新建立一个索引,将旧索引中的数据查询出来,导入新索引 这里可能会有一个问题,旧的索引名称是old_my_index,假如新的索引名称是new_my_index, 这时候已经有一个java应用在使用old_my_index在操作了, 那么这时候是不是要先停止应用,修改索引,然后重启呢? 这样的话会导致java应用停机,降低可用性 针对上面的问题呢,我们可以先给java应用一个旧索引的别名, java用的只是一个别名,指向旧的索引 1PUT /old_my_index/_alias/my_index 执行上面的代码,就是给了old_my_index一个别名(my_index),然后我们新建一个索引,将title这个field调整为string类型的 123456789101112PUT /new_my_index&#123; &quot;mappings&quot;: &#123; &quot;my_type&quot;:&#123; &quot;properties&quot;: &#123; &quot;title&quot;:&#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125;&#125; 新建完成以后,用scroll api从旧的索引中查询数据12345678GET old_my_index/my_type/_search?scroll=1m&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [&quot;_doc&quot;], &quot;size&quot;: 1&#125; 返回值:12345678910111213141516171819202122232425262728&#123; &quot;_scroll_id&quot;: &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAHVFmY1N3VWOTF4U19HUlRRUzJIbzgxcmcAAAAAAAAB1xZmNTd1VjkxeFNfR1JUUVMySG84MXJnAAAAAAAAAdQWZjU3dVY5MXhTX0dSVFFTMkhvODFyZwAAAAAAAAHYFmY1N3VWOTF4U19HUlRRUzJIbzgxcmcAAAAAAAAB1hZmNTd1VjkxeFNfR1JUUVMySG84MXJn&quot;, &quot;took&quot;: 3, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: null, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;old_my_index&quot;, &quot;_type&quot;: &quot;my_type&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;2017-01-01&quot; &#125;, &quot;sort&quot;: [ 0 ] &#125; ] &#125;&#125; 查询出来以后用bulk api将scroll查出来的一批数据,批量写入新的索引. 123POST /_bulk&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;new_my_index&quot;,&quot;_type&quot;:&quot;my_type&quot;,&quot;_id&quot;:&quot;1&quot;&#125;&#125;&#123;&quot;title&quot;:&quot;2017-01-01&quot;&#125; 重复循环scroll查询和bulk批量插入,直到所有的数据都添加到了新的索引中 添加完成后,将别名切换到新的索引上去,这样的话java应用就直接通过别名使用新的索引中的数据了,不需要停机重启,高可用 1234567891011121314151617POST /_aliases&#123; &quot;actions&quot;: [ &#123; &quot;remove&quot;: &#123; // 把别名从旧的索引上先移除 &quot;index&quot;: &quot;old_my_index&quot;, &quot;alias&quot;: &quot;my_index&quot; &#125; &#125;, &#123; &quot;add&quot;: &#123; &quot;index&quot;: &quot;new_my_index&quot;, // 将别名指向新的索引 &quot;alias&quot;: &quot;my_index&quot; &#125; &#125; ]&#125; 总结总体来说,就是最开始就给索引一个别名去让客户端去使用,然后如果要切换索引的话,就先建一个索引,然后查询旧的索引数据,将数据插入到新的索引中,完成后将别名指向新的索引,就实现了零停机重建索引]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-34-定制自己的dynamic mapping策略]]></title>
    <url>%2F2018%2F11%2F26%2FElasticsearch-34-%E5%AE%9A%E5%88%B6%E8%87%AA%E5%B7%B1%E7%9A%84dynamic-mapping%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[定制dynamic策略true: 遇到陌生字段,就进行dynamic mappingfalse: 遇到陌生字段,就忽略strict: 遇到陌生字段,就报错 示例我们现在来新建一个index.1234567891011121314151617PUT /my_index&#123; &quot;mappings&quot;: &#123; &quot;my_type&quot;: &#123; &quot;dynamic&quot;:&quot;strict&quot;, // 1 &quot;properties&quot;: &#123; &quot;title&quot;:&#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;address&quot;:&#123; &quot;type&quot;: &quot;object&quot;, &quot;dynamic&quot;:&quot;true&quot; // 2 &#125; &#125; &#125; &#125;&#125; 1处,我们设置了这个my_type的dynamic是strict,就是遇到陌生的字段,就报错2处,设置了address这个object类型的filed的dynamic是true, 遇到陌生字段就进行dynamic mapping 先来放一条数据进去123456789PUT /my_index/my_type/1&#123; &quot;title&quot;:&quot;my title&quot;, &quot;content&quot;:&quot;test content&quot;, // 1 &quot;address&quot;:&#123; &quot;province&quot;:&quot;zhejiang&quot;, // 2 &quot;city&quot;:&quot;hangzhou&quot; // 3 &#125;&#125; 1处,content这个field 我们创建索引时,并没有设置设置这个content, dynamic是strict,遇到陌生字段应该报错2,3处的province和city,我们也没有设置, address的dynamic策略应该是遇到陌生字段就进行dynamic mapping 运行上面代码,返回值:12345678910111213&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;strict_dynamic_mapping_exception&quot;, &quot;reason&quot;: &quot;mapping set to strict, dynamic introduction of [content] within [my_type] is not allowed&quot; &#125; ], &quot;type&quot;: &quot;strict_dynamic_mapping_exception&quot;, &quot;reason&quot;: &quot;mapping set to strict, dynamic introduction of [content] within [my_type] is not allowed&quot; &#125;, &quot;status&quot;: 400&#125; 报错了因为我们在my_type中设置的dynamic是strict 然后把content这个field删掉12345678PUT /my_index/my_type/1&#123; &quot;title&quot;:&quot;my title&quot;, &quot;address&quot;:&#123; &quot;province&quot;:&quot;zhejiang&quot;, &quot;city&quot;:&quot;hangzhou&quot; &#125;&#125; 执行后,添加成功. 然后我们来查询一下这个type的mapping1GET /my_index/_mapping/my_type 返回值:12345678910111213141516171819202122232425262728293031323334353637&#123; &quot;my_index&quot;: &#123; &quot;mappings&quot;: &#123; &quot;my_type&quot;: &#123; &quot;dynamic&quot;: &quot;strict&quot;, &quot;properties&quot;: &#123; &quot;address&quot;: &#123; &quot;dynamic&quot;: &quot;true&quot;, &quot;properties&quot;: &#123; &quot;city&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125;, &quot;province&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125; &#125; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125; &#125;&#125; 可以看到address中的province和city这两个字段已经被自动dynamic mapping了 定制dynamic mapping策略date_detectiones会默认按照一定的格式识别date类型,比如yyyy-MM-dd,但是如果某个field先过来一个2018-01-01的值,就会被自动dynamic mapping 成 date类型,后面如果再来一个”hello word”之类的值,就会报错.我们可以手动关闭某个type的date_detection,如果有需要,自己手动指定某个field为date类型.1234PUT /index/_mapping/type&#123; &quot;date_detection&quot;: false&#125; 定制自己的dynamic mapping template (type级别)首先我们需要在建索引的时候添加一个模板. 12345678910111213141516171819PUT /my_index&#123; &quot;mappings&quot;: &#123; &quot;my_type&quot;: &#123; // type名称 &quot;dynamic_templates&quot;:[ &#123; &quot;en&quot;:&#123; // 模板名称,自定义的 &quot;match&quot;:&quot;*_en&quot;, // 通配符匹配_en结尾的field &quot;match_mapping_type&quot;:&quot;string&quot;, &quot;mapping&quot;:&#123; &quot;type&quot;:&quot;string&quot;, &quot;analyzer&quot;:&quot;english&quot; // english分词器 &#125; &#125; &#125; ] &#125; &#125;&#125; 上面这段代码就是说 field名称是_en结尾的话,就是string类型的,分词器是english分词器 我们来添加两条数据,然后查询测试一下 123456789PUT /my_index/my_type/1&#123; &quot;title&quot;: &quot;this is my first article&quot;&#125;PUT /my_index/my_type/2&#123; &quot;title_en&quot;: &quot;this is my first article&quot;&#125; 分别用title 和 title_en去匹配 is这个词.会发现 用title_en是匹配不到的 title没有匹配到任何的dynamic模板,默认就是standard分词器,不会过滤停用词,is会进入倒排索引,用is来搜索是可以搜索到的title_en匹配到了dynamic模板,就是english分词器,会过滤停用词,is这种停用词就会被过滤掉,用is来搜索就搜索不到了 定制自己的dynamic mapping template (index级别)例: 1234567891011PUT /my_index&#123; &quot;mappings&quot;: &#123; &quot;_default_&quot;: &#123; &quot;_all&quot;: &#123; &quot;enabled&quot;: false &#125; &#125;, &quot;blog&quot;: &#123; &quot;_all&quot;: &#123; &quot;enabled&quot;: true &#125; &#125; &#125;&#125; 就是说默认的type的_all是禁用的, blog这个type的_all是启用的.]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-33-_mapping root object深入剖析]]></title>
    <url>%2F2018%2F11%2F26%2FElasticsearch-33-mapping-root-object%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[root object就是某个type对应的mapping json,包括了properties,metadata(_id,_source,_type), settings(analyzer),其他settings(比如include_in_all) 12345678PUT /index&#123; &quot;mappings&quot;: &#123; &quot;type&quot;: &#123; // 这里面的json就是这个type的 root object &#125; &#125;&#125; properties主要包括了各个field的数据类型,分不分词,用哪个分词器等. _source_source的好处: 查询的时候,可以直接拿到完整的document,不需要先拿到document id,再发送一起请求拿document. partial update是基于_source实现的. reindex时,直接基于_source实现,不需要从数据库(或者其他外部存储)查询数据再修改. 可以基于_source定制返回field. debug query更容易,因为可以直接看到_source. 如果不需要用到上面这些的话,可以禁用_source1234PUT /index/_mapping/type&#123; &quot;_source&quot;: &#123;&quot;enabled&quot;: false&#125;&#125; _all_all我们之前有详细介绍过,就是将所有field打包在一起,作为一个_all field,建立索引,没指定任何field进行搜索的时候,就是使用_all field在搜索.当然如果不需要用到的话也可以设置关闭1234PUT /index/_mapping/type&#123; &quot;_all&quot;: &#123;&quot;enabled&quot;: false&#125;&#125; 也可以在field级别设置include_in_all field,设置是否将filed的值包含在_all中123456789PUT /index/_mapping/type&#123; &quot;properties&quot;: &#123; &quot;field&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;include_in_all&quot;: false &#125; &#125;&#125; 标识性metadata包括_index,_type,_id]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-32-type底层数据结构]]></title>
    <url>%2F2018%2F11%2F26%2FElasticsearch-32-type%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[type的底层数据结构type是一个index中用来区分类似的数据的,类似的数据有可能有不同的field,而且有不同的属性来控制索引的建立 es是基于Lucene的,在es中每个field都有自己的数据类型,比如date,text等,但在底层的Lucene建立索引的时候,全部是opaque bytes类型,不区分类型的. Lucene是没有type的概念的,在document中,实际上是将type作为document的一个field类存储,即_type,es通过_type来进行过滤和筛选 一个index中的多个type,实际上是放在一起存储的,因此一个index下,不能有多个type重名. 举例说明现在,在ecommerce这个index下,有两个type,一个是elactronic_goods,另一个是fresh_goods,如下:1234567891011121314151617181920212223242526272829303132&#123; &quot;ecommerce&quot;: &#123; &quot;mappings&quot;: &#123; &quot;elactronic_goods&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &#125;, &quot;price&quot;: &#123; &quot;type&quot;: &quot;double&quot; &#125;, &quot;service_period&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &#125; &#125;, &quot;fresh_goods&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &#125;, &quot;price&quot;: &#123; &quot;type&quot;: &quot;double&quot; &#125;, &quot;eat_period&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &#125; &#125; &#125; &#125;&#125; 我们现在有两个document,分别是两个type下的数据,如下123456// type是elactronic_goods&#123; &quot;name&quot;: &quot;geli kongtiao&quot;, &quot;price&quot;: 1999.0, &quot;service_period&quot;: &quot;one year&quot;&#125; 123456// type是fresh_goods&#123; &quot;name&quot;: &quot;aozhou dalongxia&quot;, &quot;price&quot;: 199.0, &quot;eat_period&quot;: &quot;one week&quot;&#125; 这个index的底层存储是这样的:12345678910111213141516171819202122&#123; &quot;ecommerce&quot;: &#123; &quot;mappings&quot;: &#123; &quot;_type&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &quot;price&quot;: &#123; &quot;type&quot;: &quot;double&quot; &#125; &quot;service_period&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &quot;eat_period&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &#125; &#125;&#125; 可以看到type被当做了一个属性放到了document中, elactronic_goods,fresh_goods这两个type中不同的属性也被放到了一起 这两个document在底层的存储是:1234567&#123; &quot;_type&quot;: &quot;elactronic_goods&quot;, &quot;name&quot;: &quot;geli kongtiao&quot;, &quot;price&quot;: 1999.0, &quot;service_period&quot;: &quot;one year&quot;, &quot;eat_period&quot;: &quot;&quot;&#125; 1234567&#123; &quot;_type&quot;: &quot;fresh_goods&quot;, &quot;name&quot;: &quot;aozhou dalongxia&quot;, &quot;price&quot;: 199.0, &quot;service_period&quot;: &quot;&quot;, &quot;eat_period&quot;: &quot;one week&quot;&#125; 所以说,将类似结构的type放在一个index下,这些type应该有多个field是相同的. 假如说,两个type的field完全不同,放在一个index下,那么每条数据的很多field在底层的Lucene中是空置,会有严重的性能问题]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-31-手动创建索引以及定制分词器]]></title>
    <url>%2F2018%2F11%2F24%2FElasticsearch-31-%E6%89%8B%E5%8A%A8%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E4%BB%A5%E5%8F%8A%E5%AE%9A%E5%88%B6%E5%88%86%E8%AF%8D%E5%99%A8%2F</url>
    <content type="text"><![CDATA[索引创建索引语法:1234567891011121314PUT /index&#123; &quot;settings&quot;:&#123; // any settings... &#125;, &quot;mappings&quot;:&#123; type1:&#123; // any settings... &#125;, type2:&#123; // any settings... &#125; &#125;&#125; 示例: 12345678910111213141516PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1, // primary shard的数量 &quot;number_of_replicas&quot;: 0 // replica shard 的数量 &#125;, &quot;mappings&quot;: &#123; &quot;my_type&quot;:&#123; &quot;properties&quot;: &#123; &quot;field1&quot;:&#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125;&#125; 修改索引语法:1234PUT /index/_settings&#123; // any settings&#125; 示例:1234PUT /my_index/_settings&#123; &quot;number_of_replicas&quot;: 1 // 修改replica shard 的数量&#125; 删除索引1234DELETE /index DELETE /index1,index2DELETE /index_* // 通配符删除DELETE /_all // 删除全部 在elasticsearch.yml中设置action.destructive_requires_name: true,以后就不能使用 _all删除全部了 分词器修改分词器之前我们说过,es默认的分词器就是standard,他做了以下几件事:standard tokenizer:以单词边界进行切分standard token filter:什么都不做lowercase token filter:将所有字母转换为小写stop token filer(默认被禁用):移除停用词,比如a the it等等 我们先来新建一个索引,并启用english stop token filer12345678910111213PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; // 分词器相关 &quot;analyzer&quot;: &#123; // 分词器 &quot;es_std&quot;:&#123; // 自定义名称 &quot;type&quot;:&quot;standard&quot;, // 分词器类型 &quot;stopwords&quot;:&quot;_english_&quot; &#125; &#125; &#125; &#125;&#125; 执行成功后我们用之前说的测试分词器的方法来测试一下 12345GET /my_index/_analyze&#123; &quot;analyzer&quot;: &quot;es_std&quot;, // 我们上面定义的分词器名称 &quot;text&quot;: &quot;a dog is in the house&quot;&#125; 返回结果:123456789101112131415161718&#123; &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;dog&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 1 &#125;, &#123; &quot;token&quot;: &quot;house&quot;, &quot;start_offset&quot;: 16, &quot;end_offset&quot;: 21, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 5 &#125; ]&#125; 可以看到停用词已经被去掉了 定制自己的分词器我们先把创建的这个索引删除掉1DELETE /my_index 然后手动定制分词器12345678910111213141516171819202122232425262728PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;char_filter&quot;: &#123; // 字符转换 &quot;&amp;_to_and&quot;:&#123; &quot;type&quot;:&quot;mapping&quot;, &quot;mappings&quot;:[&quot;&amp; =&gt; and &quot;] //&amp; 转成 and &#125; &#125;, &quot;filter&quot;: &#123; &quot;my_stop_words&quot;:&#123; // 自定义停用词过滤 &quot;type&quot;:&quot;stop&quot;, &quot;stopwords&quot;:[&quot;the&quot;,&quot;a&quot;] // 要过滤的词 &#125; &#125;, &quot;analyzer&quot;: &#123; &quot;my_analyzer&quot;:&#123; // 自定义名称 &quot;type&quot;:&quot;custom&quot;, &quot;char_filter&quot;:[&quot;html_strip&quot;,&quot;&amp;_to_and&quot;], // html脚本过滤和上面定义的&amp;_to_and &quot;tokenizer&quot;:&quot;standard&quot;, &quot;filter&quot;:[&quot;lowercase&quot;,&quot;my_stop_words&quot;] // 大小写转换 和 上面定义的停用词过滤 &#125; &#125; &#125; &#125;&#125; 执行完毕后来测试一下 12345GET /my_index/_analyze&#123; &quot;analyzer&quot;: &quot;my_analyzer&quot;, &quot;text&quot;: &quot;tom&amp;jerry are a friend in the house, &lt;a&gt;, HAHA!!&quot;&#125; 返回值:12345678910111213141516171819202122232425262728293031323334353637383940414243444546&#123; &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;tomandjerry&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 9, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 0 &#125;, &#123; &quot;token&quot;: &quot;are&quot;, &quot;start_offset&quot;: 10, &quot;end_offset&quot;: 13, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 1 &#125;, &#123; &quot;token&quot;: &quot;friend&quot;, &quot;start_offset&quot;: 16, &quot;end_offset&quot;: 22, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 3 &#125;, &#123; &quot;token&quot;: &quot;in&quot;, &quot;start_offset&quot;: 23, &quot;end_offset&quot;: 25, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 4 &#125;, &#123; &quot;token&quot;: &quot;house&quot;, &quot;start_offset&quot;: 30, &quot;end_offset&quot;: 35, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 6 &#125;, &#123; &quot;token&quot;: &quot;haha&quot;, &quot;start_offset&quot;: 42, &quot;end_offset&quot;: 46, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 7 &#125; ]&#125; a the 这两个停用词被去掉了,&amp;也转为and了,a标签被过滤掉,最后的大写也转成了小写 使用自定义分词器上面我们自定义的分词器已经可以使用了,那么如何让type中的某个filed来使用我们自定义的分词器123456789PUT /my_index/_mapping/my_type &#123; &quot;properties&quot;: &#123; &quot;content&quot;:&#123; // field名称 &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;my_analyzer&quot; // 分词器名称 &#125; &#125;&#125;]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-30-scroll滚动查询]]></title>
    <url>%2F2018%2F11%2F24%2FElasticsearch-30-scroll%E6%BB%9A%E5%8A%A8%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[scroll查询如果我们要一次性查询10万条数据,那么性能会很差,此时一般会采用scroll滚动查询,一批一批的查,直到所有的数据都查询处理完成. 使用scroll滚动搜索,可以先搜索一批数据,然后下次再搜索一批数据,以此类推,直到搜索出全部的数据来 scroll搜索会在第一次搜索的时候,保存一个当前识图的快照,之后只会基于该旧的视图快照提供数据搜索,如果这个期间数据变更是不会让用户看到的. scroll搜索一般不会用_score相关分数去排序, 采用基于 _doc进行排序,性能比较高. 每次发送scroll请求,我们还需要指定一个scroll参数,指定一个时间窗口,每次搜索请求只要在这个时间窗口内能完成就可以了 示例在test_index/test_type下一共有5条数据,然后使用scroll滚动搜索,每次查询2条12345678910GET test_index/test_type/_search?scroll=1m&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [ &quot;_doc&quot; ], &quot;size&quot;: 2&#125; 返回值:1234567891011121314151617181920212223242526272829303132333435363738394041&#123; &quot;_scroll_id&quot;: &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAJcFmY1N3VWOTF4U19HUlRRUzJIbzgxcmcAAAAAAAACWBZmNTd1VjkxeFNfR1JUUVMySG84MXJnAAAAAAAAAlsWZjU3dVY5MXhTX0dSVFFTMkhvODFyZwAAAAAAAAJaFmY1N3VWOTF4U19HUlRRUzJIbzgxcmcAAAAAAAACWRZmNTd1VjkxeFNfR1JUUVMySG84MXJn&quot;, &quot;took&quot;: 3, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 5, &quot;max_score&quot;: null, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;AWccvc7blcpuqacodv57&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;test_content&quot;: &quot;test1&quot;, &quot;test_title&quot;: &quot;test2&quot; &#125;, &quot;sort&quot;: [ 0 ] &#125;, &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;AWcctb8Zlcpuqacodv55&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;test_content&quot;: &quot;test1&quot; &#125;, &quot;sort&quot;: [ 0 ] &#125; ] &#125;&#125; 可以看到,返回值中有一个scroll_id,下次请求时要把这个scroll_id传过去,而且要在上次查询传过去的时间窗口scroll=1m,这个时间内进行第二次查询 GET /_search/scroll { &quot;scroll&quot;:&quot;1m&quot;, &quot;scroll_id&quot;:&quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAJcFmY1N3VWOTF4U19HUlRRUzJIbzgxcmcAAAAAAAACWBZmNTd1VjkxeFNfR1JUUVMySG84MXJnAAAAAAAAAlsWZjU3dVY5MXhTX0dSVFFTMkhvODFyZwAAAAAAAAJaFmY1N3VWOTF4U19HUlRRUzJIbzgxcmcAAAAAAAACWRZmNTd1VjkxeFNfR1JUUVMySG84MXJn&quot; } scroll查询看起来挺像分页的,但是其实使用场景不一样,分页主要是用来一页一页搜索,给用户看的,scroll查询主要是用来一批一批检索数据的,让系统进行处理]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-29-搜索原理内核解析]]></title>
    <url>%2F2018%2F11%2F24%2FElasticsearch-29-%E6%90%9C%E7%B4%A2%E5%8E%9F%E7%90%86%E5%86%85%E6%A0%B8%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[query phase假设我们有一个index里面的数据分布在3个primary shard上(对应的replica也有),现在总共有7个shard,我们现在要搜索这个index中的数据的第10000条到10010条.如图所示 请求发送给某一个shard时,这个shard就是coordinate node, coordinate node会构建一个 priority queue,队列长度是查询时的from和size的和,默认是0 + 10 = 10; 我们要查询的是10000-10010条数据,所以请求的from = 9999,size = 10,这个时候coordinate node会在它本地建立一个长度是 9999 + 10 = 10009 的 priority queue, 然后coordinate node将请求打到其他的shard上去 接收到请求的每个shard,也会在本地建立一个 from + size大小的priority queue,每个shard将自己下标是0 - 10009的数据放到这个队列中, 也就是10010条数据,返回给coordinate node. coordinate node 将返回的所有数据进行合并,合并成一份from * size大小的priority queue,全局排序后,放到自己队列中去 最后在自己的队列中取出当前要获取的那一页的数据. 这里也可以看出我们之前提到过的deep paging问题,就是说,from * size分页太深,那么每个shard都要返回大量的数据给coordinate node,消耗大量的带宽,内存, CPU fetch phase在上面的query phase的工作处理完成之后,coordinate node 在priority queue里面找到了需要的数据, 但是其实这个队列时存的document的id, 这个时候,coordinate node就发送mget请求(批量查询)到所有shard上去获取对应的document 然后各个shard将document返回给coordinate node, coordinate node将合并后的document结果返回给客户端 bouncing results问题比如说有两个document,field值相同;但是分布在不同的shard上面,在不同的shard上可能排序也不相同, 每次请求轮询打到不同的shard上去,页面上看到的搜索结果的排序可能都不一样, 这就是 bouncing results,也就是跳跃的结果. preferencepreference 决定了哪些shard会执行搜索请求. bouncing results问题解决将preference设置为一个字符串,比如说user_id,让每个user每次搜索的时候,都使用同一个shard去执行,就不会看到bouncing results了]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-28-doc values初步了解]]></title>
    <url>%2F2018%2F11%2F23%2FElasticsearch-28-doc-values%E5%88%9D%E6%AD%A5%E4%BA%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[doc value搜索的时候,要依靠倒排索引去搜索,但是在排序的时候需要依靠正排索引,找到每个document的每个field,然后进行排序,所谓的正排索引,其实就是doc values es在建立索引的时候,一方面会建立倒排索引,以供搜索使用;一方面还会建立正排索引,也就是doc values,以供排序,聚合,过滤等操作使用 doc values是被保存在磁盘上的,此时如果内存足够,os会自动将其缓存在内存中,性能还是很高的,如果内存不够,os会将其写入到磁盘上 举例比如有两个document,数据如下document1: { “name”: “jack”, “age”: 27 }document2: { “name”: “tom”, “age”: 30 } 在es建立正排索引的时候就是这样子的 document name age document1 jack 27 document2 ton 30 这样在排序的时候es直接拿到正排索引里面的某一列去排序就好了]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-27-搜索相关度TF&IDF算法]]></title>
    <url>%2F2018%2F11%2F23%2FElasticsearch-27-%E6%90%9C%E7%B4%A2%E7%9B%B8%E5%85%B3%E5%BA%A6TF-IDF%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[算法介绍relevance score算法,简单来说就是计算出一个索引中的文本,与搜索文本,他们之间的关联匹配程度 Elasticsearch使用的是 term frequency/inverse document frequency算法，简称为TF/IDF算法 TF算法(Term frequency)Term frequency:搜索文本中的各个词条在field文本中出现了多少次,出现次数越多就越相关 举个例子:搜索请求是: hello worlddocument1:hello you, and world is very gooddocument2:hello, how are you hello和world这两个词在document1中出现了两次,document2中出现了一次,所以document更相关 IDF算法(inverse document frequency)inverse document frequency: 搜索文本中的各个词条在整个索引的所有document中出现了多少次,出现的次数越多,就越不相关 举例:搜索请求是:hello worlddocument1:hello, today is very gooddocument2:hi world, how are you 看起来hello和world是每个document都出先一次,但是这个应该是document2更相关 比如说在index中现在有一万条document,hello这个单词在所有的document中出现了1000次,world这个单词在所有的document中出现了100次,所以document2就更相关 Field-length normField-length norm: field的值长度越长,相关度越弱 举例:搜索请求:hello worlddocument1: { “title”: “hello article”, “content”: “babaaba…..(1万个单词)” }document2: { “title”: “my article”, “content”: “blablabala…. (1万个单词),hi world” }这个时候hello 和 world这两个词在整个index中出现的次数是一样多的,但是document1更相关,因为title这个filed中的数据短 查询_score是如何被计算出来的语法:12345678GET /index/type/_search?explain&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;field&quot;: &quot;text&quot; &#125; &#125;&#125; 分析一个document是如何被匹配上的语法:12345678GET /index/type/id/_explain&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;field&quot;: &quot;text&quot; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-26-字符串排序问题及解决方案]]></title>
    <url>%2F2018%2F11%2F23%2FElasticsearch-26-%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%8E%92%E5%BA%8F%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[字符串排序问题如果对一个string类型的field进行排序,结果往往不准确,因为string类型的field要进行分词,分词后是多个单词,再排序就不是我们想要的结果了 如何解决通常解决方式是,将一个string类型的field建立两次索引,一个分词用来进行搜索,一个不分词用来排序 示例我们之前建立过一个website的索引,先把它删除掉1DELETE /website 然后重新建立索引并手动创建mapping.12345678910111213141516171819202122232425262728PUT /website&#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;:&#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; // 这里是重点,title里面在建立一个 string类型的field &quot;raw&quot;:&#123; // 名称 &quot;type&quot;: &quot;string&quot;, // 数据类型,不分词只能是string &quot;index&quot;: &quot;not_analyzed&quot; // 指定不分词 &#125; &#125;, &quot;fielddata&quot;: true // 建立正排索引,这个后面详细说 &#125;, &quot;content&quot;:&#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;post_date&quot;:&#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;author_id&quot;:&#123; &quot;type&quot;: &quot;long&quot; &#125; &#125; &#125; &#125;&#125; 建立好之后,往里面添加点数据 1234567891011121314151617181920212223PUT /website/article/1&#123; &quot;title&quot;: &quot;second article&quot;, &quot;content&quot;: &quot;this is my second article&quot;, &quot;post_date&quot;: &quot;2017-02-01&quot;, &quot;author_id&quot;: 110&#125;PUT /website/article/2&#123; &quot;title&quot;: &quot;first article&quot;, &quot;content&quot;: &quot;this is my frist article&quot;, &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;author_id&quot;: 110&#125;PUT /website/article/3&#123; &quot;title&quot;: &quot;third article&quot;, &quot;content&quot;: &quot;this is my third article&quot;, &quot;post_date&quot;: &quot;2017-03-01&quot;, &quot;author_id&quot;: 110&#125; 数据添加完成,我们来查询按照title排序一下12345678910111213GET /website/article/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [ &#123; &quot;title&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125; ]&#125; 返回结果:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: null, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;third article&quot;, &quot;content&quot;: &quot;this is my third article&quot;, &quot;post_date&quot;: &quot;2017-03-01&quot;, &quot;author_id&quot;: 110 &#125;, &quot;sort&quot;: [ &quot;third&quot; ] &#125;, &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;second article&quot;, &quot;content&quot;: &quot;this is my second article&quot;, &quot;post_date&quot;: &quot;2017-02-01&quot;, &quot;author_id&quot;: 110 &#125;, &quot;sort&quot;: [ &quot;second&quot; ] &#125;, &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;first article&quot;, &quot;content&quot;: &quot;this is my frist article&quot;, &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;author_id&quot;: 110 &#125;, &quot;sort&quot;: [ &quot;first&quot; ] &#125; ] &#125;&#125; 可以看到 返回值中的sort这一列,是按照分词之后进行排序的,然后用我们上面创建出来title.raw来进行排序看下效果12345678910111213GET /website/article/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [ &#123; &quot;title.raw&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125; ]&#125; 返回值:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: null, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;third article&quot;, &quot;content&quot;: &quot;this is my third article&quot;, &quot;post_date&quot;: &quot;2017-03-01&quot;, &quot;author_id&quot;: 110 &#125;, &quot;sort&quot;: [ &quot;third article&quot; ] &#125;, &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;second article&quot;, &quot;content&quot;: &quot;this is my second article&quot;, &quot;post_date&quot;: &quot;2017-02-01&quot;, &quot;author_id&quot;: 110 &#125;, &quot;sort&quot;: [ &quot;second article&quot; ] &#125;, &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;first article&quot;, &quot;content&quot;: &quot;this is my frist article&quot;, &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;author_id&quot;: 110 &#125;, &quot;sort&quot;: [ &quot;first article&quot; ] &#125; ] &#125;&#125; 再来看一下返回值中的sort ,这样排序就没有分词而是直接去排序的]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-25-Query DSL常用查询]]></title>
    <url>%2F2018%2F11%2F23%2FElasticsearch-25-Query-DSL%E5%B8%B8%E7%94%A8%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[Query DSL的常用的几种查询语法match all查询查询全部123456GET /index/type/_search&#123; &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;&#125; match查询指定field搜索条件查询, 搜索的关键词会被分词12345678GET /_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;field&quot;: &quot;text&quot; &#125; &#125;&#125; multi match搜索条件在多个field上进行查询, 搜索条件也会被分词123456789GET /_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;text&quot;, &quot;fields&quot;: [&quot;field1&quot;,&quot;field2&quot;] &#125; &#125;&#125; range query在区间范围内查询1234567891011GET /_search&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &#123; &quot;gte&quot;: 0, &quot;lte&quot;: 10 &#125; &#125; &#125;&#125; term query搜索条件不去进行分词查询,同样的,只能查询设置为不分词的field12345678GET /_search&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;field&quot;: &quot;text&quot; &#125; &#125;&#125; terms query一个field 去匹配多个值1234567891011GET /_search&#123; &quot;query&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: [ &quot;text1&quot;, &quot;text2&quot; ] &#125; &#125;&#125; filter之前有说过filter是不计算相关度分数的,就是直接把符合条件的数据筛选出来如果只用filter过滤的话 需要加”constant_score” 例:123456789101112131415GET _search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &#123; &quot;gte&quot;: 10, &quot;lte&quot;: 20 &#125; &#125; &#125; &#125; &#125;&#125; 定位搜索不合法的原因语法:1234GET index/type/_validate/query?explain&#123; // 搜索条件&#125; 示例我们先来写一个错误的查询来试一下12345678GET test_index/test_type/_validate/query?explain&#123; &quot;query&quot;: &#123; &quot;math&quot;: &#123; // 应该是match 写成了 math &quot;test_field&quot;: &quot;text&quot; &#125; &#125;&#125; 返回值:1234&#123; &quot;valid&quot;: false, &quot;error&quot;: &quot;org.elasticsearch.common.ParsingException: no [query] registered for [math]&quot;&#125; 再来试一个正确的12345678GET test_index/test_type/_validate/query?explain&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;test_field&quot;: &quot;text&quot; &#125; &#125;&#125; 返回值:123456789101112131415&#123; &quot;valid&quot;: true, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;explanations&quot;: [ &#123; &quot;index&quot;: &quot;test_index&quot;, &quot;valid&quot;: true, &quot;explanation&quot;: &quot;+test_field:text #(#_type:test_type)&quot; &#125; ]&#125; 一般用在那种特别复杂庞大的搜索下，比如你一下子写了上百行的搜索，这个时候可以先用validate api去验证一下，搜索是否合法 定制排序规则默认情况下,es是按照_score去排序的,然后某些情况下,可能没有有用的 _score,比如说filter ,那么我们如何使用自己的排序规则呢? 语法:12345678910111213GET /index/type/_search&#123; &quot;query&quot;:&#123; ... &#125;, &quot;sort&quot;:[ &#123; &quot;field&quot;:&#123; &quot;order&quot;:&quot;desc&quot; &#125; &#125; ]&#125; 就是在query后面加一个sort来进行排序,指定用哪一个field,和升序还是降序]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-24-search api和Query DSL基本语法]]></title>
    <url>%2F2018%2F11%2F22%2FElasticsearch-24-search-api%E5%92%8CQuery-DSL%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[search api 的基本语法12GET /_search&#125;&#123; 12345GET /_search&#123; &quot;from&quot;:0, &quot;size&quot;:10&#125; 1GET /_search?from=0&amp;size=10 可以直接将参数拼接在url请求上,也可以放在request body中 在HTTP协议中,一般不允许GET请求带上reques body,但是因为GET请求更加适合描述查询数据的操作,因此还是这么用了,很多浏览器,或者是服务器,也都支持GET+request body模式,如果遇到不支持的场景，也可以用POST请求12345POST /_search&#123; &quot;from&quot;:0, &quot;size&quot;:10&#125; Query DSL基本语法:123456789101112131415&#123; QUERY_NAME: &#123; ARGUMENT: VALUE, ARGUMENT: VALUE,... &#125;&#125;&#123; QUERY_NAME: &#123; FIELD_NAME: &#123; ARGUMENT: VALUE, ARGUMENT: VALUE,... &#125; &#125;&#125; 示例12345678GET /test_index/test_type/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; // 查询条件 &quot;test_field&quot;: &quot;test&quot; &#125; &#125;&#125; 组合多个搜索条件示例我们先来添加几个document 用来进行搜索123456789101112131415161718192021PUT /query_index/query_type/1&#123; &quot;title&quot;: &quot;my elasticsearch article&quot;, &quot;content&quot;: &quot;es is very bad&quot;, &quot;author_id&quot;: 110&#125;PUT /query_index/query_type/2&#123; &quot;title&quot;: &quot;my hadoop article&quot;, &quot;content&quot;: &quot;hadoop is very bad&quot;, &quot;author_id&quot;: 111&#125;PUT /query_index/query_type/3&#123; &quot;title&quot;: &quot;my elasticsearch article&quot;, &quot;content&quot;: &quot;es is very goods&quot;, &quot;author_id&quot;: 111&#125; 然后我们制定一个搜索条件,比如 我们要查询 title必须包含 elasticsearch ,content 可以包含 elasticsearch 也可以不包含,author_id必须不为111 我们先来看一下数据: title必须包含 elasticsearch : id是2和3的数据都符合 content 可以包含 elasticsearch 也可以不包含: 2和3中都没有包含, author_id必须不为111: 3的id是111根据这几个条件来看搜索结果就是id为1的那一条数据,然后我们来组合搜索条件进行搜索 12345678910111213141516171819202122232425262728GET /query_index/query_type/_search&#123; &quot;query&quot;: &#123; // 查询 &quot;bool&quot;: &#123; // 组合查询条件 &quot;must&quot;: [ // 必须符合的条件 &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;elasticsearch&quot; &#125; &#125; ], &quot;should&quot;: [ // 可以符合,也可以不符合的条件 &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;elasticsearch&quot; &#125; &#125; ], &quot;must_not&quot;: [ // 必须不符合的条件 &#123; &quot;match&quot;: &#123; &quot;author_id&quot;: 111 &#125; &#125; ] &#125; &#125;&#125; 执行后的结果: 1234567891011121314151617181920212223242526&#123; &quot;took&quot;: 3, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 0.25316024, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;query_index&quot;, &quot;_type&quot;: &quot;query_type&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.25316024, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;my elasticsearch article&quot;, &quot;content&quot;: &quot;es is very bad&quot;, &quot;author_id&quot;: 110 &#125; &#125; ] &#125;&#125; 只返回了id是1的数据 query 与 filter示例我们现在有三条数据,如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&#123; &quot;_index&quot;: &quot;company&quot;, &quot;_type&quot;: &quot;emp&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;address&quot;: &#123; &quot;country&quot;: &quot;china&quot;, &quot;province&quot;: &quot;jiangsu&quot;, &quot;city&quot;: &quot;nanjing&quot; &#125;, &quot;name&quot;: &quot;tom&quot;, &quot;age&quot;: 30, &quot;join_date&quot;: &quot;2016-01-01&quot; &#125;&#125;,&#123; &quot;_index&quot;: &quot;company&quot;, &quot;_type&quot;: &quot;emp&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;jack&quot;, &quot;age&quot;: 27, &quot;join_date&quot;: &quot;2017-01-01&quot;, &quot;address&quot;: &#123; &quot;country&quot;: &quot;china&quot;, &quot;province&quot;: &quot;zhejiang&quot;, &quot;city&quot;: &quot;hangzhou&quot; &#125; &#125;&#125;,&#123; &quot;_index&quot;: &quot;company&quot;, &quot;_type&quot;: &quot;emp&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;address&quot;: &#123; &quot;country&quot;: &quot;china&quot;, &quot;province&quot;: &quot;shanxi&quot;, &quot;city&quot;: &quot;xian&quot; &#125;, &quot;name&quot;: &quot;marry&quot;, &quot;age&quot;: 35, &quot;join_date&quot;: &quot;2015-01-01&quot; &#125;&#125; 现在有一个搜索请求, 搜索年龄必须大于等于30,同时join_date必须是2016-01-01 我们来构造一个包含query和filter的搜索请求123456789101112131415161718192021GET /company/emp/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; // 组合搜索 &quot;must&quot;: [ // 必须满足的条件 &#123; &quot;match&quot;: &#123; &quot;join_date&quot;: &quot;2016-01-01&quot; &#125; &#125; ], &quot;filter&quot;: &#123; // 过滤器 &quot;range&quot;: &#123; &quot;age&quot;: &#123; &quot;gte&quot;: 30 &#125; &#125; &#125; &#125; &#125;&#125; 返回值: 12345678910111213141516171819202122232425262728293031&#123; &quot;took&quot;: 16, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;company&quot;, &quot;_type&quot;: &quot;emp&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;address&quot;: &#123; &quot;country&quot;: &quot;china&quot;, &quot;province&quot;: &quot;jiangsu&quot;, &quot;city&quot;: &quot;nanjing&quot; &#125;, &quot;name&quot;: &quot;tom&quot;, &quot;age&quot;: 30, &quot;join_date&quot;: &quot;2016-01-01&quot; &#125; &#125; ] &#125;&#125; 可以看到搜到了一条满足条件的数据. query 与 filter 对比 filter:仅仅只是按照搜索条件过滤出需要的数据而已,不计算任何相关度分数,对相关度没有任何影响. query: 会去计算每个document相对于搜索条件的相关度,并按照相关度进行排序. 一般来说,我们在搜索的时候需要将最匹配的数据先返回的时候,就用query,如果只是需要根据条件筛选出一些数据,不关注其相关度,就用filter 除非你的这些搜索条件,你希望越符合这些搜索条件的document越排在前面,那么这些搜索条件要放到query中去.如果你不希望一些搜索条件来影响你的document排序的话,那么就放在filter中即可 query 与 filter 性能filter不需要计算相关度分数进行排序,同时还有内置的cache,自动缓存最常使用的filter数据query相反,要计算相关度分数,按照分数进行排序,而且无法cache结果]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-23-_mapping复杂数据类型和object类型底层数据存储]]></title>
    <url>%2F2018%2F11%2F22%2FElasticsearch-23-mapping%E5%A4%8D%E6%9D%82%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%92%8Cobject%E7%B1%BB%E5%9E%8B%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[几种复杂的数据类型multivalue field比如数据是1&#123;&quot;tags&quot;:[&quot;tag1&quot;,&quot;tag2&quot;]&#125; 这种数据建立索引时,与string类型是一样的, 数组中的数据是不能混的,要放字符串都放字符串. empty field比如 null, [], [null]这样的数据 object field我们先来添加一个document1234567891011PUT /company/emp/1&#123; &quot;name&quot;:&quot;jack&quot;, &quot;age&quot;:27, &quot;join_date&quot;:&quot;2017-01-01&quot;, &quot;address&quot;:&#123; &quot;country&quot;:&quot;china&quot;, &quot;province&quot;:&quot;zhejiang&quot;, &quot;city&quot;:&quot;hangzhou&quot; &#125;&#125; 像上面这个address就是object类型的, 我们来看一下这个type的_mapping1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&#123; &quot;company&quot;: &#123; &quot;mappings&quot;: &#123; &quot;emp&quot;: &#123; &quot;properties&quot;: &#123; &quot;address&quot;: &#123; &quot;properties&quot;: &#123; &quot;city&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125;, &quot;country&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125;, &quot;province&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125; &#125; &#125;, &quot;age&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125;, &quot;join_date&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 可以看到 address中的每个field都有对应的type等 其实像我们刚才添加的这个document,它的数据在es底层是像这样存储的12345678&#123; &quot;name&quot;:[jack], &quot;age&quot;:[27], &quot;join_date&quot;:[2017-01-01], &quot;address.country&quot;:[china], &quot;address.province&quot;:[zhejiang], &quot;address.city&quot;:[hangzhou]&#125; 再比如有更复杂的数据,比如下面我们再加一个,数据是1234567&#123; &quot;authors&quot;: [ &#123; &quot;age&quot;: 26, &quot;name&quot;: &quot;Jack White&quot;&#125;, &#123; &quot;age&quot;: 55, &quot;name&quot;: &quot;Tom Jones&quot;&#125;, &#123; &quot;age&quot;: 39, &quot;name&quot;: &quot;Kitty Smith&quot;&#125; ]&#125; 像这种包含json数组的数据,底层会从横向转为列式存储,就像这样1234&#123; &quot;authors.age&quot;: [26, 55, 39], &quot;authors.name&quot;: [jack, white, tom, jones, kitty, smith]&#125; 就是一列存在一起]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-22-mapping详解]]></title>
    <url>%2F2018%2F11%2F22%2FElasticsearch-22-mapping%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[什么是mapping往es里面直接插入数据,es会自动建立索引,同时建立type以及对应的mapping. mapping中就定义了每个field的数据类型 不同的数据类型,可能有的是精确搜索(exact value),有的是全文检索(full text). exact value在建立倒排索引的时候,分词是将整个值一起作为一个关键词建立到倒排索引中的;而full text是会经过各种处理的,分词 normalization 才会建立到倒排索引中. 一个搜索过来的时候对exact value field或者是full text field进行搜索的行为也是不一样的,会跟建立倒排索引的行为保持一致;比如说exact value搜索的时候,就是直接按照整个值进行匹配;full text query string,也会进行分词和normalization再去倒排索引中去搜索 可以用es的dynamic mapping 让其自动建立mapping,包括自动设置数据类型,也可以提前手动创建index的type的mapping,自己对各自的field进行设置,包括数据类型,索引行为,分词器等等. 总结: mapping,就是index的type的元数据,每个type都有一个自己的mapping,决定了数据类型,建立倒排索引的行为,还有进行搜索的行为 核心数据类型mapping 下的核心数据类型有: 字符串: String整型: byte, short, integer, long浮点型: float, double布尔型: boolean日期类型: date dynamic mapping 数据类型映射 数据 映射后的数据类型 true/fasle boolean 123 long 123.45 double 2017-01-01 date “hello world” string/text 查询mapping语法:1GET /index/_mapping/type 手动建立mapping只能在创建index的时候手动建立mapping,或者新增field mapping, 不能修改 filed mapping 之间我们建立过一个website的index,我们先删掉.1DELETE /website 现在来手动建立这个索引,并手动创建mapping1234567891011121314151617181920212223242526PUT /website&#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;author_id&quot;:&#123; // field &quot;type&quot;: &quot;long&quot; // 类型 &#125;, &quot;title&quot;:&#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;english&quot; // 指定分词器 &#125;, &quot;content&quot;:&#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;post_date&quot;:&#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;publisher_id&quot;:&#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; // 不分词,就是 exact value ,上面的类型一定要写string,否则不生效 &#125; &#125; &#125; &#125;&#125; analyzed:分词not_analyzed:不分词no:直接不建立到倒排索引里,也就是说 搜索不到 好了,创建完成,然后我们来尝试修改一下这个mapping.123456789101112PUT /website&#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;author_id&quot;:&#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125;&#125; 返回值:1234567891011121314151617&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;index_already_exists_exception&quot;, &quot;reason&quot;: &quot;index [website/-6NKQPj3TPWDrrlxhalkmw] already exists&quot;, &quot;index_uuid&quot;: &quot;-6NKQPj3TPWDrrlxhalkmw&quot;, &quot;index&quot;: &quot;website&quot; &#125; ], &quot;type&quot;: &quot;index_already_exists_exception&quot;, &quot;reason&quot;: &quot;index [website/-6NKQPj3TPWDrrlxhalkmw] already exists&quot;, &quot;index_uuid&quot;: &quot;-6NKQPj3TPWDrrlxhalkmw&quot;, &quot;index&quot;: &quot;website&quot; &#125;, &quot;status&quot;: 400&#125; 运行后发现,报错了,原因就是建立好的field mapping是不能去修改的,但是我们可以新增一个field,并指定type等123456789PUT /website/_mapping/article&#123; &quot;properties&quot;: &#123; &quot;new_field&quot;:&#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125; &#125;&#125; 返回值:123&#123; &quot;acknowledged&quot;: true&#125; 可以看到已经新增成功了. 测试mapping完成后我们测试一下分词的效果, content这个field是普通的text类型,我们来测试一下12345GET /website/_analyze&#123; &quot;field&quot;: &quot;content&quot;, &quot;text&quot;: &quot;my-dogs&quot;&#125; 返回值:123456789101112131415161718&#123; &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;my&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 2, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 0 &#125;, &#123; &quot;token&quot;: &quot;dogs&quot;, &quot;start_offset&quot;: 3, &quot;end_offset&quot;: 7, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 1 &#125; ]&#125; 可以看到my-dogs 被拆分为 my dogs,去掉了 - ,没有进行单复数转换等,因为默认的分词器就是standard analyzer(标准分词器) 再来试一下new_field,我们在设置的时候这个filed是不能分词的12345GET website/_analyze&#123; &quot;field&quot;: &quot;new_field&quot;, &quot;text&quot;: &quot;my dogs&quot;&#125; 返回值:12345678910111213&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;remote_transport_exception&quot;, &quot;reason&quot;: &quot;[f57uV91][127.0.0.1:9300][indices:admin/analyze[s]]&quot; &#125; ], &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Can&apos;t process field [new_field], Analysis requests are only supported on tokenized fields&quot; &#125;, &quot;status&quot;: 400&#125; 报错了,因为这个field是不能分词的.]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-21-query string分词和mapping案例遗留问题揭秘]]></title>
    <url>%2F2018%2F11%2F22%2FElasticsearch-21-query-string%E5%88%86%E8%AF%8D%E5%92%8Cmapping%E6%A1%88%E4%BE%8B%E9%81%97%E7%95%99%E9%97%AE%E9%A2%98%E6%8F%AD%E7%A7%98%2F</url>
    <content type="text"><![CDATA[query string 分词query string必须以和index建立时相同的analyzer进行分词. 比如,我们有一个document,其中有一个field,它的值是:hello you and me,建立倒排索引.我们要搜索这个document对应的index,搜索文本是hello me ,搜索请求就是:1GET /index/type/_search?q=field:hello me “hello me”就是query string,默认情况下,es会使用它对应的field建立倒排索引时相同的分词器进行分词和normalization,只有这样,才能实现正确的搜索. 举个例子,document在建立倒排索引的时候,会把dogs转为dog,然后我们在搜索的时候传一个dogs过去,就找不到了,所以搜索传过去的dogs也必须变为dog才能实现正确的搜索. mapping引入案例遗留问题揭秘这里有一个知识点: 不同类型的field,可能有的就是full text(全文检索),有的就是exact value(精确搜索) 在初始mapping中,我们引入了一个小案例,当时的查询结果是:1234GET /website/article/_search?q=2017 3条结果 GET /website/article/_search?q=2017-01-01 3条结果GET /website/article/_search?q=post_date:2017-01-01 1条结果GET /website/article/_search?q=post_date:2017 1条结果 首先看第一个查询,我们没有指定用哪一个field进行查询,那默认的就是 _all 查询,之前有说过 _all的话会把document中的所有field的值当做字符串拼接, _all搜索的时候是full text,要分词进行normalization后查询 我们来看一下第一个document中的数据:123456&#123; &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;title&quot;: &quot;my first article&quot;, &quot;content&quot;: &quot;this is my first article in this website&quot;, &quot;author_id&quot;: 11400&#125; 它的_all就是 “2017-01-01 my first article this is my first article in this website 11400” 三个document的 _all中分别有 2017-01-01 2017-01-02 2017-01-03 这个建立倒排索引就是 word document1 document2 document3 2017 √ √ √ 01 √ 02 √ 03 √ 这时候第一个搜索 _all 查询2017 肯定能查到3条第二个搜索请求的query string 会被分为 2017,01,01, 所以也能查到3条数据 然后是第三个请求,是指定post_date这个filed去查询, post_date 是个date类型的,而不是字符串类型, date类型的数据会按照exact value去建立索引 word document1 document2 document3 2017-01-01 √ 2017-01-02 √ 2017-01-03 √ 所以搜索第三个请求时可以搜索到1条结果. 按照上面的说法的话,第4个请求应该是搜索不到结果的,但是实际上有一条结果,这个在这里不讲解,因为是es 5.2以后做的一个优化 分词器测试12345GET /_analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, // 指定分词器 &quot;text&quot;: &quot;Text to analyze&quot; // 要拆分的文本&#125;]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-20-分词器详解]]></title>
    <url>%2F2018%2F11%2F22%2FElasticsearch-20-%E5%88%86%E8%AF%8D%E5%99%A8%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[什么是分词器作用: 拆分词语,进行normalization操作(提升recall召回率) 比如说,有一个句子,然后将这个句子拆分成一个一个的单词,同时对每个单词进行normalization(时态转换,单复数转换等等). recall召回率:简单来说就是搜索的时候,增加能够搜索到的结果的数量. 分词器一共做了三件事:character filter:在一段文本进行分词之前,先进行预处理,比如说过滤html标签(&lt;span&gt;123&lt;/span&gt; 转换为123), &amp; 转换为 andtokenizer:分词,比如 hello me 分为 hello 和 metoken filter:进行大小写转换,停用词去掉,近义词转换等normalization操作,比如 dogs –&gt; dog, liked –&gt; like, Tom –&gt; tom, a/an/the去掉,等等 分词器很重要,讲一段文本进行各种处理,最后处理好的结果才会拿去建立倒排索引. 内置分词器的介绍比如某个document中的某一个field的值是: Set the shape to semi-transparent by calling set_trans(5) standard analyzer(标准分词器) :将句子拆分为set, the, shape, to, semi, transparent, by, calling, set_trans, 5,做了大写转小写,-去除,()去除等操作 simple analyzer(简单分词器):拆分为set,the,shape,to,semi,transparent,by,calling,set,trans,可以看到做了大写转小写，-去除，(5)去除，_去除 等操作 whitespace analyzer(空格分词器)：Set,the,shape,semi-transparent,by,calling,set_trans(5), 简单的按照空格进行分词 language analyzer(语言分词器，比如说英语分词器)：set,shape,semi,transpar,call,set_tran,5,可以看到大写转小写,the没有任何含义,被干掉了,以及一些拆分的,transparent转换成了transpar,calling转化时态call,等等 默认的分词器是standard analyzer(标准分词器)]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-19-倒排索引核心原理]]></title>
    <url>%2F2018%2F11%2F21%2FElasticsearch-19-%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[场景假设我们现在有两个document. document1: I really liked my small dogs, and I think my mom also liked them. document2: He never liked any dogs, so I hope that my mom will not expect me to liked him. 第一步 分词,初步建立倒排索引两个document中的数据将会被分词,比如分成这样 word document1 document2 I √ √ really √ liked √ √ my √ √ small √ dogs √ and √ think √ mom √ √ also √ them √ He √ never √ any √ so √ hope √ that √ will √ not √ expect √ me √ to √ him √ 这个时候我们如果搜索 mother like little dog 的时候,不会有任何结果的先回对搜索条件拆词,拆分为motherlikelittledog 这个时候去上面的倒排索引去匹配,发现没有一个词是可以匹配的到的. 这显然不是我门想要的搜索结果 其实建立倒排索引的时候,还会做一件事,就是进行normalization标准化,包括时态转换，复数，同义词，大小写等,对拆出的各个单词进行相应的处理,以便后面搜索的时候能够搜索到相关联document的概率 进行normalization后的倒排索引: word document1 document2 normalization I √ √ really √ like √ √ liked – &gt;like my √ √ little √ small –&gt; little dog √ √ dogs –&gt; dog and √ think √ mom √ √ also √ them √ He √ never √ any √ so √ hope √ that √ will √ not √ expect √ me √ to √ him √ 这时候再按上面的搜索条件 mother like little dog 搜索,将搜索条件分词,进行normalization后mother –&gt; momlike –&gt; likelittle –&gt; littledog –&gt; dog 这时候拿关键词去匹配上面的倒排索引,就能把document1和document2都搜索出来]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-18-精确匹配与全文检索]]></title>
    <url>%2F2018%2F11%2F21%2FElasticsearch-18-%E7%B2%BE%E7%A1%AE%E5%8C%B9%E9%85%8D%E4%B8%8E%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[精确匹配(exact value)比如我们在之前的例子,通过精确匹配搜索 2017-01-01的时候, field中必须包含2017-01-01 才能搜索出来,如果只搜索个01,这样是搜不出来的 全文检索 (full text)不单纯的只是匹配一个完整的值,而是可以对值进行分词后进行匹配,还可以通过缩写 时态 大小写 同义词等进行匹配 缩写搜索比如查询 cn 可以将 China 搜索出来 格式转换比如查询 likes 可以将 like liked 搜索出来 大小写转换比如查询 tom 可以将 Tom 搜索出来 同义词搜索比如查询 love 它的同义词 like 也可以搜索出来]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-17-初识mapping]]></title>
    <url>%2F2018%2F11%2F21%2FElasticsearch-17-%E5%88%9D%E8%AF%86mapping%2F</url>
    <content type="text"><![CDATA[首先,我们先插入几条数据,让ES为我们自动建立一个索引1234567891011121314151617181920212223PUT /website/article/1&#123; &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;title&quot;: &quot;my first article&quot;, &quot;content&quot;: &quot;this is my first article in this website&quot;, &quot;author_id&quot;: 11400&#125;PUT /website/article/2&#123; &quot;post_date&quot;: &quot;2017-01-02&quot;, &quot;title&quot;: &quot;my second article&quot;, &quot;content&quot;: &quot;this is my second article in this website&quot;, &quot;author_id&quot;: 11400&#125;PUT /website/article/3&#123; &quot;post_date&quot;: &quot;2017-01-03&quot;, &quot;title&quot;: &quot;my third article&quot;, &quot;content&quot;: &quot;this is my third article in this website&quot;, &quot;author_id&quot;: 11400&#125; 对这些数据进行几次搜索_all 搜索 20171GET /website/article/_search?q=2017 返回值:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#123; &quot;took&quot;: 3, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: 0.28004453, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.28004453, &quot;_source&quot;: &#123; &quot;post_date&quot;: &quot;2017-01-02&quot;, &quot;title&quot;: &quot;my second article&quot;, &quot;content&quot;: &quot;this is my second article in this website&quot;, &quot;author_id&quot;: 11400 &#125; &#125;, &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.28004453, &quot;_source&quot;: &#123; &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;title&quot;: &quot;my first article&quot;, &quot;content&quot;: &quot;this is my first article in this website&quot;, &quot;author_id&quot;: 11400 &#125; &#125;, &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 0.28004453, &quot;_source&quot;: &#123; &quot;post_date&quot;: &quot;2017-01-03&quot;, &quot;title&quot;: &quot;my third article&quot;, &quot;content&quot;: &quot;this is my third article in this website&quot;, &quot;author_id&quot;: 11400 &#125; &#125; ] &#125;&#125; 一共查询出来3条结果 指定 post_date 搜索20171GET /website/article/_search?q=post_date:2017 返回值:123456789101112131415161718192021222324252627&#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;title&quot;: &quot;my first article&quot;, &quot;content&quot;: &quot;this is my first article in this website&quot;, &quot;author_id&quot;: 11400 &#125; &#125; ] &#125;&#125; 一共查询出来1条结果 _all 搜索 2017-01-011GET /website/article/_search?q=2017-01-01 返回值:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#123; &quot;took&quot;: 9, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: 1.0566096, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1.0566096, &quot;_source&quot;: &#123; &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;title&quot;: &quot;my first article&quot;, &quot;content&quot;: &quot;this is my first article in this website&quot;, &quot;author_id&quot;: 11400 &#125; &#125;, &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.84013355, &quot;_source&quot;: &#123; &quot;post_date&quot;: &quot;2017-01-02&quot;, &quot;title&quot;: &quot;my second article&quot;, &quot;content&quot;: &quot;this is my second article in this website&quot;, &quot;author_id&quot;: 11400 &#125; &#125;, &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 0.84013355, &quot;_source&quot;: &#123; &quot;post_date&quot;: &quot;2017-01-03&quot;, &quot;title&quot;: &quot;my third article&quot;, &quot;content&quot;: &quot;this is my third article in this website&quot;, &quot;author_id&quot;: 11400 &#125; &#125; ] &#125;&#125; 一共查询出来3条结果 指定 post_date 搜索2017-01-011GET /website/article/_search?q=post_date:2017-01-01 返回值:123456789101112131415161718192021222324252627&#123; &quot;took&quot;: 3, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;title&quot;: &quot;my first article&quot;, &quot;content&quot;: &quot;this is my first article in this website&quot;, &quot;author_id&quot;: 11400 &#125; &#125; ] &#125;&#125; 一共查询出来1条结果 总体结果:1234GET /website/article/_search?q=2017 3条结果 GET /website/article/_search?q=2017-01-01 3条结果GET /website/article/_search?q=post_date:2017-01-01 1条结果GET /website/article/_search?q=post_date:2017 1条结果 mapping 概念自动或手动为index中的type建立的一种数据结构相关的配置,简称为mappingdynamic mapping自动为我们建立index,创建type,以及type对应的mapping,mapping中包含了每个field对应的数据类型,以及如何分词等设置 查询mapping查询语法:1GET /index/_mapping/type 比如查询我们上面例子中的mapping1GET /website/_mapping/article 返回值:12345678910111213141516171819202122232425262728293031323334&#123; &quot;website&quot;: &#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;author_id&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125;, &quot;post_date&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 可以看到 里面包含了我们每个field的数据类型等信息. 搜索结果为什么不一致?因为es自动建立mapping的时候,设置了各个filed的数据类型,不同的数据类型的分词 搜索等行为是不一样的,所以出现了_all 搜索和指定field搜索时的数据不一致的情况]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-16-_search搜索详解]]></title>
    <url>%2F2018%2F11%2F21%2FElasticsearch-16-_search%E6%90%9C%E7%B4%A2%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[multi-index和multi-type搜索模式就是一次性搜索多个index和type下的数据 示例 搜索所有index,所有type下的所有数据 1GET /_search 指定一个index,搜索其下所有的type的数据 1GET /index/_search 查询某个index下指定的type的数据 1GET /index/type/_search 同时搜索多个index下的所有数据 1GET /index1,index2,index3,.../_search 按照通配符去匹配多个index 12GET /*1,*2/_search# 查询以 1 和 2 结尾的index 搜索一个index下指定的多个type的数据 1GET /index/type1,type2/_search 搜索多个index下的多个type的数据 1GET /index1,index2/type1,type2/_search 搜索所有index下的指定type的数据 1GET /_all/type1,type2/_search 搜索原理客户端发送一个请求,会把请求打到所有的primary shard上去执行,因为每个shard都包含部分数据,所以每个shard上都可能包含搜索请求的结果但是如果primary shard有replica shard,那么请求也可以打到replica shard上面 分页搜索查询时传入参数 size 和 from 即可 示例比如我们要查询movies/movie下的数据一共是6条,分三页查询12345678# 查询第一页GET /movies/movie/_search?size=2&amp;from=0# 查询第二页GET /movies/movie/_search?size=2&amp;from=2# 查询第三页GET /movies/movie/_search?size=2&amp;from=4 from 是从0开始的 deep paging问题什么是deep paging问题? 为什么会产生这个问题? 他的底层原理是什么? 场景,比如我们现在有4个shard 一共有60000条数据,在其中3个shard中,每个有20000条数据,这个时候要进行搜索第1000页的数据,每页显示10条,实际上这里拿到的是第10001~10010条数据 假设这个请求先打到一个不包含这些数据的节点上去,那么这个节点就是一个协调节点(coordinate node),然后这个协调节点会将请求转发到包含数据的节点上去,如图: 查询60000条数据中的第1000页,实际上每个shard都要将内部的20000条数据中的1000页,也就是10001~10010条的数据拿出来, 这时候实际上不是只返回这10条数据 是返回第一条到10010条数据, 3个shard都返回10010条数据给coordinate node,coordinate node 总共会受到30030条数据,然后进行排序,在这30030条数据中取到第10页,也就是这些数据中的第10001~10010条数据返回. 总的来说就是先要把所有shard上的数据集中起来排序后再去分页. 搜索过深的时候,就要在coordinate node上保存大量的数据,还要进行排序,排序之后,再取出对应的那一页,所以这个过程,既耗费网络带宽,耗费内存,还耗费CPU,影响性能,我们应该尽量避免出现这种deep paging的操作 query string其实就是在http请求中,把一些搜索的参数做为query string附加到url上面. 示例查询 /movies/movie 下title包含kill这个词的数据1GET /movies/movie/_search?q=title:kill 查询 /movies/movie 下title必须包含kill这个词的数据1GET /movies/movie/_search?q=+title:kill 查询/movies/movie 下title不包含kill这个词的数据1GET /movies/movie/_search?q=-title:kill 其实第一个和第二个的作用是差不多的,主要是 “+” 和 “-“ 的区别 一个是必须包含,一个是不包含 _all metadata 原理和作用查询所有filed下包含kill的数据1GET /movies/movie/_search?q=kill 上面这个查询中并没有指定具体是哪个field包含kill这个词,是直接搜索的所有field的.当我们添加一个document的时候,它里面包含了多个field,此时es会自动将多个field的值,用字符串的方式串联起来,变成一个长字符串,作为_all 的值,同时对 _all进行分词建立索引.当我们搜索没有指定具体哪一个field的时候,就默认对_all 进行搜索,其实它里面就包含了所有field的值 举例说明我们新添加一个document,内容是123456&#123; &quot;name&quot;:&quot;jack&quot;, &quot;age&quot;:26, &quot;email&quot; : &quot;jack@sina.com&quot;, &quot;address&quot;:&quot;hangzhou&quot;&#125; “jack 26 jack@sina.com hangzhou”,就作为这一条document的_all元数据的值,同时进行分词后建立对应的倒排索引]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-15-写一致性原理及quorum机制]]></title>
    <url>%2F2018%2F11%2F20%2FElasticsearch-15-%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E5%8F%8Aquorum%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[概念我们在发送任何一个增删改操作的时候,都可以带上一个consistency参数,指明我们想要的写一致性是什么,比如:1PUT /index/type/id?consistency= consistency的值可以有三个: one:要求这个写操作,只要有一个primary shard是active活跃可用的状态就可以执行. all:要求这个写操作,必须所有的primary shard和replica shard都是active活跃的,才可以执行 quorum:默认的值,要求所有的shard中,必须大部分的shard都是active活跃的,才可以执行. 那么怎么算大部分shard都是活跃的呢,es有一个计算的公式 quorum机制前置条件当replica shard 的数量大于1的时候才会生效 计算公式12quorum = int((number_of_priamry_shard + number_of_replica_shard) / 2) + 1# 这里的number_of_replica_shard是相对于 primary shard的数量 举例说明如果现在有3个primary shard, number_of_replica_shard = 3, 也就是说一共有3 + 3 * 3 = 12个shard,根据公式, int((3 + 3) / 2) + 1 = 4 意思就是说,在所有的12个shard中必须是有4个shard是active状态的才可以执行写操作 如果节点的数量少于quorum数量,可能导致quorum不齐全,进而导致无法执行任何写操作 特殊场景处理如果说我们就一个primary shard,replica = 1,此时总共就两个shard,按照公式int((1 + 1) / 2) + 1 = 2,此时要求两个shard都是活跃的才行,但是我们可能就有一个节点,只能有一个primary shard,那么这个情况下是不是就无法写入了呢? es提供了一种特殊的处理场景,就是说当number_of_replicas &gt; 1的时候才生效,如果没有这种特殊处理的话,单节点集群就无法正常工作. 超时等待当quorum不齐全时, 会默认等待一分钟,等待期间,期望活跃的shard数量可以增加,时间到了还不能添加的话就超时.我们也可以在写操作的时候,加一个timeout的参数,比如1PUT /index/type/id?timeout=30ms 就是说我们自己去设定当quorum不齐全的时候es的timeout时长.]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-14-document增删改查原理]]></title>
    <url>%2F2018%2F11%2F20%2FElasticsearch-14-document%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[熟悉了es路由规则以后,再来看一下document的增删改查的原理. 场景现在有3个es节点在一个集群内, 有3个primary shard 对应的replica数量是1 就是说有3个 primary shard 和3个replica,总共6个shard, 现在有个客户端要创建一个document到es中 增删改操作客户端随便选择一个node,然后将请求发送到node上去, 因为任意一个node都知道document应该存在哪个shard上,所以请求发给哪一个都是一样的. 比如图中,请求节点到达node1了,那node就成为了coordinate node(协调节点),协调节点通过我们之前说到的路由公式,来计算这个document应该在哪个shard上面,然后将请求发送到这个节点上去, 比如应该放到shard2 中, shard2在自己本地创建document,创建倒排索引,创建完毕后会将数据同步到他对应的replica上去 写入完毕 同步数据到replica完成后,通知协调节点,然后协调节点返回响应给客户端 查询操作客户端先发送一个查询请求到任意的一个node上去 如图,请求发到node1 上去后node1就成为了coordinate node(协调节点) ,协调节点对document进行路由,路由之后就知道document在哪个primary shard上了,对于读请求,不一定就将请求转发到primary shard上去,因为replica shard也可以承担读请求的 es采用round-robin随机轮询算法在primary shard以及其所有replica中随机选择一个，让读请求负载均衡. 然后对应的shard去查询,将查询结果返回给协调节点,协调节点最后响应给客户端 特殊情况如果查询的document还在建立索引的过程中,这个时候只有primary shard上有,任何一个replica shard上都没有,此时如果请求路由到replica shard上可能会导致无法读取到document,但是document完成索引建立 将数据同步到replica shard上之后,就都有了]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-13-document路由原理]]></title>
    <url>%2F2018%2F11%2F20%2FElasticsearch-13-document%E8%B7%AF%E7%94%B1%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[概念我们知道,一个index的数据会被分为多片,每片都放在一个shard中.所以,一个document只能存在于一个shard中.当客户端创建document的时候,es此时就要决定这个document是要放在哪一个shard中. 这个过程就被是document routing 数据路由 路由算法12shard = hash(routing) % number_of_primary_shards# routing的哈希值 除以 primary shard的数量,然后取余. 每次增删改查一个document的时候,都会带过来一个routing number,默认的就是这个document的id(可以是手动指定,也可以是自动生成). 举个例子,现在有一个index,有3个shard P0 P1 P2,假设routing = _id, _id = 1, es会将这个routing值传入一个hash函数中,返回一个routing值的hash值, 假如hash(routing) = 21, 然后将hash函数产出的值对这个index的primary shard的数量求余数, 21 % 3 = 0,就决定了这个document应该放在P0上面. 决定一个document在哪个shard上,最重要的一个值就是routing值,默认是id也可以手动指定,相同的routing值,每次过来,从hash函数中产出的hash值一定是相同的 无论hash值是多少,无论是什么数字,对number_of_primary_shard求余数,结果一定是在0~number_of_primary_shard-1 这个范围之内的. 再来想想我们之前说过,primary shard的数量在创建完index之后是不能去修改的,还是上面那个例子,数据被放到了P0中,如果现在加了一个primary shard的数量会怎么样呢.我们去查询这个document的时候,_id = 1, hash值还是21, 21 % 4 = 1,计算结果是数据在P1上面,但是实际在P0上,就会间接导致数据的丢失. routing值的作用和如何手动指定默认的routing就是_id,也可以在发送请求的时候,手动指定一个routing ,如下:1PUT /index/type/id?routing=user_id 手动指定routing是很有用的,可以保证说,某一类的document一定被路由到一个shard上去,那么在后续进行应用级别的负载均衡,以及提升批量读取的性能的时候,是很有帮助的]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-12-批量增删改查操作]]></title>
    <url>%2F2018%2F11%2F19%2FElasticsearch-12-%E6%89%B9%E9%87%8F%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[批量查询批量查询的优点: 如果用 GET /index_name/type_name/id 这样的查询去查询100条数据的话,就要发送100次网络请求,开销比较大,如果是批量查询的话,查询100条数据只需要用1次网络请求,网络请求的性能开销会很少. _mget批量查询比如我们要查询test_index/test_type下面 id是1和2的两条数据执行代码:123456789101112131415GET /_mget&#123; &quot;docs&quot;:[ &#123; &quot;_index&quot;:&quot;test_index&quot;, // 索引名 &quot;_type&quot;:&quot;test_type&quot;, // 类型名 &quot;_id&quot;:1 // id &#125;, &#123; &quot;_index&quot;:&quot;test_index&quot;, &quot;_type&quot;:&quot;test_type&quot;, &quot;_id&quot;:2 &#125; ] &#125; 返回值:12345678910111213141516171819202122232425&#123; &quot;docs&quot;: [ &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;test_content&quot;: &quot;test content&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;num&quot;: 1, &quot;tags&quot;: [] &#125; &#125; ]&#125; GET请求后面直接跟_mget端点, 将参数封装在一个docs数组里面,数组中的一个元素就是一个请求条件, 执行后返回值也封装在了一个docs数组中,一个元素对应一个返回结果. 如果说查询的是同一个index下的不同type的数据,直接将请求跟在url上就可以了,请求体中值需要指明type 和 id即可12345678910111213GET /test_index/_mget&#123; &quot;docs&quot;:[ &#123; &quot;_type&quot;:&quot;test_type&quot;, // 类型名称 &quot;_id&quot;:1 // id &#125;, &#123; &quot;_type&quot;:&quot;test_type&quot;, &quot;_id&quot;:2 &#125; ] &#125; 如果查询的是同一个index下的同一个type下的内容,那么index和type都写在url上,请求体中只需要一个ids的数组即可1234GET /test_index/test_type/_mget&#123; &quot;ids&quot;:[1,2]&#125; 可以看出来ids不需要包在docs中, 但是返回值还是会包在docs数组中. 总结:一般来说,在进行查询的时候,如果一次要查询多条数据的话,一定要用batch批量操作的api,尽可能减少网络请求的开销,可以大大提升性能. _bulk批量增删改_bulk 可以操作批量增删改,语法如下:12&#123;&quot;action&quot;:&#123;&quot;metadata&quot;&#125;&#125;&#123;&quot;data&quot;&#125; bulk api对json的语法有严格的要求,每个json不能换行,只能放一行,同时一个json和另一个json之间必须换行,每个操作需要两个json字符串,删除操作只需要一个. 举例,比如现在要创建一个document,放到bulk里面是这样的12&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;test_index&quot;,&quot;_type&quot;:&quot;test_type&quot;,&quot;_id&quot;:1&#125;&#125;&#123;&quot;test_field&quot;:&quot;test1&quot;,&quot;test_field2&quot;:&quot;test2&quot;&#125; 那么有哪些类型的操作可以执行呢? delete:,删除一个document create:相当于 PUT /index/type/id/_create,强制创建 index:普通的PUT操作,可以是创建,也可以是全量替换 update:相当于 partial update操作 示例:12345678POST /_bulk&#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;test_index&quot;,&quot;_type&quot;:&quot;test_type&quot;,&quot;_id&quot;:3&#125;&#125;&#123;&quot;create&quot;:&#123;&quot;_index&quot;:&quot;test_index&quot;,&quot;_type&quot;:&quot;test_type&quot;,&quot;_id&quot;:2&#125;&#125;&#123;&quot;test_field&quot;:&quot;already exists&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;test_index&quot;,&quot;_type&quot;:&quot;test_type&quot;,&quot;_id&quot;:1&#125;&#125;&#123;&quot;test_field&quot;:&quot;replace all&quot;&#125;&#123;&quot;update&quot;:&#123;&quot;_index&quot;:&quot;test_index&quot;,&quot;_type&quot;:&quot;test_type&quot;,&quot;_id&quot;:4,&quot;_retry_on_conflict&quot;:3&#125;&#125;&#123;&quot;doc&quot;:&#123;&quot;test_content&quot;:&quot;update id is4&quot;&#125;&#125; 上面这个请求中: 删除了id为4document 强制创建一个document,id为2 (id为2的已经存在了) 将id为1的document全量替换 partial update更新id为4的document,更新失败的时候重试3次 执行返回结果:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&#123; &quot;took&quot;: 79, &quot;errors&quot;: true, &quot;items&quot;: [ &#123; &quot;delete&quot;: &#123; &quot;found&quot;: true, &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_version&quot;: 2, &quot;result&quot;: &quot;deleted&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;status&quot;: 200 &#125; &#125;, &#123; &quot;create&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;status&quot;: 409, &quot;error&quot;: &#123; &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[test_type][2]: version conflict, document already exists (current version [2])&quot;, &quot;index_uuid&quot;: &quot;qFba3qxtTO6YxlO3m7qtug&quot;, &quot;shard&quot;: &quot;2&quot;, &quot;index&quot;: &quot;test_index&quot; &#125; &#125; &#125;, &#123; &quot;index&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: false, &quot;status&quot;: 200 &#125; &#125;, &#123; &quot;update&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_version&quot;: 2, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;status&quot;: 200 &#125; &#125; ]&#125; 可以看到,第2个操作失败了,原因是已经存在了,但是其他操作仍然执行成功了,所以bulk操作中，任意一个操作失败，是不会影响其他的操作的，但是在返回结果里，会告诉你异常日志 bulk size最佳大小bulk request会加载到内存里面,如果太大的话,性能反而会下降,因此需要反复尝试一个最佳的bulk size. 一般从1000~5000 条数据开始,或者数据大小在5~15MB之间,尝试逐渐增加 奇特的json格式详解上面有说过bulk的请求体 每个json不能换行,只能放一行,同时一个json和另一个jso之间必须换行,那为什么要这样设计呢? 第一点,bulk中的操作都可能要转发到不同的node的shard去执行.第二,如果允许任意换行,es拿到json后就得进行如下处理: 将json数组解析为JSONArray对象,这个时候,整个数据就会在内存中出现两份,一份是json文本,一份是JSONArray对象 解析json数组里的每个json,对每个请求中的document进行路由 为路由到一个shard上的多个请求,创建一个请求数组 将这个请求数组进行序列化 将序列化后的请求数组发送到对应的节点上去 所以按照这种方式的话,会耗费更多的内存,更多的jvm gc开销上文中有说到过bulk size的最佳大小,如果说现在有100个bulk请求,每个请求10MB,那就是 1000MB的数据,每个请求的json都copy一份为JSONArray对象,此时内存中的占用就会翻倍,会占用到2000MB+的内存,占用更多的内存就可能积压其他请求的内存使用量,就可能导致其他请求的性能急速下降. 另外,占用更多的内存,gc回收次数更多,每次要回收的垃圾对象更多,耗费的时间更多,会导致es的java虚拟机停止工作线程的时间更多 使用这种不换行的格式的话 不需要转为json对象,不会在内存中copy数据,直接按照换行符切割即可 对每两个一组的json,读取metadata,进行document路由. 直接将对应的json发送到node上去 最大的优势在于,不需要将json数组解析为JSONArray对象,不需要浪费内存空间,尽可能保证性能]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-11-基于groovy脚本进行partial update]]></title>
    <url>%2F2018%2F11%2F19%2FElasticsearch-11-%E5%9F%BA%E4%BA%8Egroovy%E8%84%9A%E6%9C%AC%E8%BF%9B%E8%A1%8Cpartial-update%2F</url>
    <content type="text"><![CDATA[基于groovy脚本进行partial update首先添加一条数据到es中12345PUT test_index/test_type/2&#123; &quot;num&quot;:0, &quot;tags&quot;:[]&#125; 内置脚本1234POST test_index/test_type/2/_update&#123; &quot;script&quot;: &quot;ctx._source.num+=1&quot;&#125; 通过ctx._source.filed 去操作filed的值 执行完毕后去查询一下1GET test_index/test_type/2 返回值:1234567891011&#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;num&quot;: 1, &quot;tags&quot;: [] &#125;&#125; 可以看到num已经变成了1 外部脚本用外部脚本进行partial update首先要在es的config/scripts目录下新建groovy脚本,比如我们要在tags下加一个值,新建脚本test-add-tags.groovy,文件内容是1ctx._source.tags+=new_tag 然后用外部脚本进行更新12345678910POST test_index/test_type/2/_update&#123; &quot;script&quot;: &#123; &quot;lang&quot;: &quot;groovy&quot;, // 指定脚本语言 &quot;file&quot;: &quot;test-add-tags&quot;, // 文件名称(不包含文件后缀名) &quot;params&quot;: &#123; // 参数的集合 &quot;new_tag&quot;:&quot;tag1&quot; // 参数名和值 &#125; &#125;&#125; 用外部脚本删除document同样需要在config/scripts目录下新建groovy脚本, 脚本名称:test-delete-document,脚本内容是:1ctx.op=ctx._source.num == count ? &apos;delete&apos; : &apos;none&apos; 就是num的值跟count相等的时候才删除,如果不相等,什么都不做.然后执行partial update12345678910POST test_index/test_type/2/_update&#123; &quot;script&quot;: &#123; &quot;lang&quot;: &quot;groovy&quot;, &quot;file&quot;: &quot;test-delete-document&quot;, &quot;params&quot;: &#123; &quot;count&quot;:1 &#125; &#125;&#125; 传入的参数count是1,这个时候document中的num的值也是1,所以这document会被删除掉 upsert操作此时这个id是2的document已经被删除,如果这个时候直接去进行partial update,会报错,因为这个document不存在这时候可以使用upsert去进行初始化操作执行:12345678POST /test_index/test_type/2/_update&#123; &quot;script&quot;: &quot;ctx._source.num+=1&quot;, &quot;upsert&quot;: &#123; &quot;num&quot;:0, &quot;tags&quot;:[] &#125;&#125; 执行完成后,查询发现num是0 tags是[],并没有去执行script中的脚本.再次运行上面的代码, 查询后发现num已经更新为1 upsert操作:如果指定的document不存在,就执行upsert中的初始化操作,如果指定的document存在,就执行doc或者script中指定的partial update操作.]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-10-并发控制方案]]></title>
    <url>%2F2018%2F11%2F17%2FElasticsearch-10-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[并发场景假设现在是矮子电商场景下,用户需要去购买商品,程序的工作流程是: 读取商品信息,比如商品名称价格等. 用户下单去购买商品 更新商品库存es的工作流程: 先查询document数据,商品信息等,显示到页面,同时在内存中缓存该document的数据 当网页发生购买以后,直接基于内存中的数据进行计算和操作 将计算后的结果返回到es中 现在有两个线程同时去执行这个流程,比如购买一台电脑库存是100,线程A 线程B并发执行,两个线程查询到的库存都是100,这个时候用户去下单购买,线程A 将商品库存减一是99件,线程B也将库存减一也是99件,然后A先更新es的中的商品库存,更新为99,此时线程B也去更新商品库存为99,这个时候一共是发生了两次购买操作,正常结果是库存应该减少两件,但其实只减少了一件,这就导致了并发冲突,使得数据结果不正确. 有些场景下,在不管数据正不正确的情况下这样操作是无所谓,比如我们只管将数据写入es,不管数据是什么样的,或者是说算错了也没关系的这些情况,但是一般情况下我们是需要做并发控制的防止数据错乱 并发控制方案悲观锁并发控制方案还是上面的这个场景,使用悲观锁控制并发,就是线程A去读取商品信息,读取的时候给这个商品信息加锁,然后进行一系列的操作,比如减少库存等,将库存减一后,再更新到商品信息中去,然后释放锁,在这个过程中,线程B如果去请求这个商品数据是请求不到的,在线程A释放锁之前,B是获取不到的,当A释放锁之后,这个时候商品库存已经变化了,B拿到的数据就是A已经操作完成后的数据,同时线程B也会对数据加锁,操作完成之后再释放. 悲观锁的并发控制方案,就是在各种情况下都上锁,上锁之后,就只有一个线程可以操作这条数据了,当然,不同场景下上的锁也不同,比如行级锁 表级锁 读锁 写锁等. 乐观锁并发控制方案es就是使用的乐观锁,使用乐观锁控制并发的时候,并不会对数据进行加锁,而是通过版本号控制(version),这点和zookeeper相似,还是上面的场景,线程A B 同时去请求商品信息,然后拿到的都是一样的,比如库存是100, 这时候比如数据的version=1, 假设线程A先把库存-1然后更新到es中,这时候es会拿版本号和线程A中的数据的版本号进行对比,这时候version都是1写入成功,库存更新为99 es中数据的版本号变更为2,这时候线程B也去进行更新,发现es中数据的版本号是2,但是线程B的版本号还是1,版本号不同的情况下,线程B重新请求es的数据 然后再将库存-1,版本号也变为2,然后再去更新es中的数据,这个时候库存变为98 版本号变为3. es内部基于乐观锁控制并发的原理假设现在有两个节点一个shard一个replica,里面有一条document 数据是test1 version也是1 现在有两个请求同时去修改document数据,我们期待的结果是1先修改为test2,然后2再修改为test3 但是这个两个请求时并发的所以第2个请求可能先到达es先进性修改, 如果没有乐观锁并发控制的话,第2个请求先到达将内容修改为test3,第1个请求后到,再去修改为test2,这个时候数据就变成了test,跟我们预期的结果就不一样了,因为按照顺序来说是先修改为test2 再修改为test3 同理shard去将数据同步到replica的时候也会多线程异步执行的,如果没有乐观锁的控制,数据也可能发生错误但是在有乐观锁的情况下,基于version去控制,如果说第二个请求先到先修改了数据 version已经加1了比如变为2,replica先同步了第二个请求的数据,第一个请求再去同步的时候去比对一下版本号,version还是1,那么es就会直接把这条数据扔掉,这个时候数据就会保持一个正确的状态 基于external version进行乐观锁并发控制es提供了一个feature,就是说你可以不用他提供的内部版本号来进行并发控制,可以基于你自己维护的一个版本号来进行并发控制.举个例子,假如你的数据在mysql里面也有一份,然后你的应用本身就维护了一个版本号,无论是自己生成的或者是程序控制的.这个时候进行乐观锁并发控制的时候可能并不是想要用内部的_version来进行控制,而是用你自己维护的那个版本号来控制. 基于内部的_version进行控制时,只需要在请求后面加 _version=版本号即可,基于自己的version控制的话需要在请求后面加?_version=版本号&amp;version_type=external这两种版本控制的唯一区别就在于 基于内部_version控制时,只有当你提供的version和es中的version一毛一样的时候才能修改,只要不一样就报错,而基于自己的版本号控制时,只有当你提供的version比es中的_version大的时候才能完成修改 两种锁的优缺点 悲观锁 优点:方便,直接加锁,对应用程序来说是透明的,不需要做额外的操作 缺点:并发能力很低,同一时间只能有一个线程访问操作数据 乐观锁 优点:并发能力高,不给数据加锁,可以有大量线程并发操作 缺点:麻烦,每次更新的时候都要先去比对版本号,然后版本号不一致时,可能需要重新加载数据,再次修改然后再写,而且这个过程可能要重复好几次]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-9-document核心元数据解析]]></title>
    <url>%2F2018%2F11%2F16%2FElasticsearch-9-document%E6%A0%B8%E5%BF%83%E5%85%83%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本文主要写document中的_index,_type,_id,_source这几个元数据先随便添加一个document1234PUT /test_index/test_type/1&#123; &quot;test_content&quot;:&quot;test content&quot;&#125; 查询1GET /test_index/test_type/1 返回值12345678910&#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;test_content&quot;: &quot;test content&quot; &#125;&#125; 返回值详解_index元数据 代表document存放在哪一个index中 类似的数据放在一个索引中,非类似的数据应该放到不同的索引中,什么意思呢,比如现在有一个商品类的数据(product)和一个商品销售的数据(sale),那么应该把product的数据放到一个index里面,sale的数据放到另一个index里面, 如果把所有的数据都放到一个index里面,这样做是不合适的. index中包含了很多类似的document,类似就是指这些document的fields很大一部分是相同的, 比如说现在有3个document但是每个document里面的fields是完全不一样的,这就是不类似的,就不太适合放到同一个index里面了 索引的命名规则,必须是小写的 不能用大写,第二 不能用下划线开头,第三 不能包含逗号 详细来说一下上面的第2点,为什么说应该把类似的数据放到同一个index里面, 比如我们现在把product的数据和sale的数据都放到了同一个index下, 这些数据将会被分配到不同的shard上面,每个shard上面既有product数据也有sale数据, 现在网站后台需要做sale的聚合分析,而且sale的数据量很大,这个时候所有的shard都会去执行这次聚合分析,耗费大量的资源,与此同时在网站前端用户需要去搜索product中的数据,因为这些shard都在做后台的聚合分析占用了大量的资源,导致前端用户搜索product数据时会变慢,影响用户体验,所以相同类型的数据放到一个index上,在自己独立的shard中与其他数据不在一个shard中就不会互相影响 _type元数据 代表document属于index中的哪个类别 一个索引通常会划分为多个type,逻辑上对index中有些许不同的数据进行分类,因为相同类型的数据,会有很多相同的fields,但是也可能有些许的差别,比如商品数据放到了一个index中,但是商品下面还划分为电子商品 生鲜商品 等等. type命名 名称是可以大小写的,但是不能用下划线开头也不能包含逗号 _id元数据 代表document的唯一标识,与index和type一起,可以定位一个document 我们可以手动指定document的id,也可以不指定 es会为我们自动创建一个id Q:什么时候适合使用手动生成id,什么时候使用自动生成的id?A:一般来说是从某些其他的系统中导入数据到es时,会采取这种方式,就是系统中已经有数据的唯一标识了,比如我们现在有一个商品的数据库,要把里面的数据导入到es里面做搜索,数据库里面肯定会有一个数据的主键primary key,这时将数据导入到es中的时候就适合用数据库中已有的primary key做id自动生成的id,我们先来看一下,是什么样的先添加一个数据,不指定id1234POST /test_index/test_type&#123; &quot;test_content&quot;:&quot;test1&quot;&#125; 返回值:12345678910111213&#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;AWcctb8Zlcpuqacodv55&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true&#125; 可以看到id是一个字符串,长度是固定为20位的,URL安全,base64编码,使用的是GUID生成策略,分布式系统并行生成时不可能发生冲突 _source元数据就是我们在创建document的时候,在request中写入的json数据,当我们get的时候,会把这个json数据原封不动的返回到_source中来.如果我们发送的有多个field 在返回时只想要指定的field 只需要在get请求后面加?_source=field1,field2…即可]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-8-容错机制]]></title>
    <url>%2F2018%2F11%2F16%2FElasticsearch-8-%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[容错机制假设场景,现在一共有9个shard,其中3个shard 6个replica,一共有三个es节点,node1是master节点,具体如下图: 如果下载master节点挂掉,shard1,replica2-1,replica3-1 节点会丢失,在master节点挂掉的一瞬间 shard1就没了,此时shard1就不是active状态了,集群中不是所有的primary shard都是active状态了,所以集群的状态会在这一瞬间变为red 容错第一步集群会自动选举另外一个node成为新的master,比如node2,承担起master的责任来 容错第二步新的master会将丢失掉的primary shard的某个replica shard提升为primary shard,此时集群的状态是yellow了,因为所有的primary shard都变成了活跃状态, 但是因为少了一个replica shard 所以不是所有的replica shard都是active状态了 容错第三步新的master重启之前宕机的节点,将丢失的副本都拷贝到该node上去,而且该node会使用宕机之前已有的shard的数据,只是同步一下宕机后发生的修改.此时集群的状态变为green,因为所有的primary shard 和 replica shard都是active状态了]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-7-扩容机制]]></title>
    <url>%2F2018%2F11%2F16%2FElasticsearch-7-%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[横向扩容上文中有提到有两个es节点的环境下shard和replica的分配 两个node环境下replica和shard的分配目前集群中有两个es节点,创建一个index,设置有3个shard每个shard对应一个replica,如下图: 新添加一个节点到集群中前面有说到过es集群会自动做负载均衡,如果我们现在加一个es节点到集群中来的话,es会按照一定的规则(一个shard和它对应的replica不会被分配到同一个节点上去)将部分shard分配到新的节点上去,如图: 横向扩容的好处横向扩容后,每台节点上的shard会减少,就意味着每个shard可以占用节点上的更多资源比如IO/CPU/Memory,整个系统的性能会更好 扩容的极限上面我们一共有6个shard(3个shard 3个replica),最多扩容到6个节点,就是说每个节点上都有一个shard,这个时候每个shard可以占用他所在服务器的所有资源,性能是最好的 突破扩容瓶颈如何超出系统的扩容瓶颈呢, 比如现在我们有6个shard但是要扩容到9个节点,同时想让系统的性能更好,这个时候我们可以增加replica的数量,因为primary shard的数量是不能变的,我们只能改变replica的数量,比如有3个primary shard,设置replica的数量为2, 这个时候总共有 3 + 3 x 2 = 9个shard 就可以分布到9个节点上去,因为 replica 也可以处理读请求 所以整个集群的性能会更好. 集群容错性比如集群中有3个节点,一共6个shard,这个时候 如果某一个节点宕机,比如node3宕机了,如下图: 这个时候shard3 和 replica1已经丢失了,剩下其他两个节点上的shard1 replica2 shard2 replica3 ,replica3 因为replica3 是shard3的副本,所以node3 宕机是是不会造成数据的丢失的, 所以3个shard 3个replica分布在3个节点上任意一个节点宕机都不会造成数据的丢失]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-6-shard&replica机制]]></title>
    <url>%2F2018%2F11%2F16%2FElasticsearch-6-shard-replica%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[shard&amp;replica机制梳理 一个index可以包含多个shard, index中的数据会均匀的分配到每个shard中,就是es分片的机制. 每个shard都是一个最小的工作单元,承载部分数据,es是基于Lucene去开发的,其实每个shard就是Lucene的实例,有完整的建立索引和处理请求的能力 增减节点的时候shard会自动在nodes中负载均衡,比如一共有6个es节点,但是有7个shard 这个时候其中的一个es节点会有两个shard,如果这时候集群中再加进来一个es节点,那么承载两个shard的节点会分配一个shard到新加的节点上去 每个document肯定只会存在于某一个primary shard中以及其对应的replica shard中,不可能同时存在于两个 primary shard中 replica shard是primary shard的副本,负责容错,以及承担读请求负载. primary shard的数量在创建索引的时候就固定了,replica shard的数量可以随时修改 一个index中primary shard的默认数量是5,replica shard默认是1(就是每个primary shard都有1个 replica),默认有10个shard 5个primary shard和5个replica shard primary shard不能和自己的replica shard放在同一个节点上,如果放在同一个节点上 当这个节点宕机的时候primary shard和replica shard都丢失了,就起不到容错的作用, 同一个节点上一个放其他节点的replica shard 单个es节点环境下创建index比如我们现在创建一个index 设置有3个primary shard 每个 shard对应一个replica创建代码如下:1234567PUT /test_index&#123; &quot;settings&quot; : &#123; &quot;number_of_shards&quot; : 3, &quot;number_of_replicas&quot; : 1 &#125;&#125; 这时候es集群的状态是yellow,而且只会将3个primary shard分配到这个es节点上去,对应的3个replica是不会被创建的,就是上面提到的 shard自己的replica是不能跟自己放在一起的,此时集群可以正常工作,但是这个节点一旦宕机的话,数据就会全部丢失,而且集群不可用,无法承接任何请求 两个es节点环境下shard的分配在上面单节点的环境下如果在添加一个es节点到集群中, 此时新添加进来的节点会承载之前节点的primary shard的replica shard, primary shard 和 replica shard中的数据是一样的, replica 和 primary shard 同样可以处理读请求.]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-5-基础分布式架构]]></title>
    <url>%2F2018%2F11%2F16%2FElasticsearch-5-%E5%9F%BA%E7%A1%80%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[上文中写了Elasticsearch的聚合分析,下钻分析,嵌套聚合等, 本文主要是写Elasticsearch的分布式机制, 扩容策略等 Elasticsearch对分布式机制的透明隐藏特性Elasticsearch是一套分布式的系统,分布式是为了应对大数据量 分片机制: 往ES插入数据的时候ES集群会自动分配到某一shard上,比如 之前用rest API插入数据时,我们并没有关心数据是怎么分配的,是分配到哪个shard上的 cluster discovery:集群发现机制,就是新启动一个es节点时,集群会自动发现节点并加入集群. shard负载均衡:比如我们现在有3个es节点,总共要有25个shard要分配到3个节点上去,es会自动进行均匀分配,以保持每个节点均衡的读写负载请求 shard副本 请求路由:将请求自动路由到对应处理的shard上 集群扩容 shard重分配 我们在实际使用中并不需要关心这些,Elasticsearch会自动处理 Elasticsearch的垂直扩容与水平扩容假设现在有6台服务器,每台服务器容量是1T,马上数据量要增长到8T,这个时候有两种方案: 垂直扩容:重新购置两台服务器,每台服务器的容量是2T,替换两台老的服务器,那么现在服务器总容量就是 4x1T + 2x2T =8T 水平扩容:新购置两台服务器,每台容量1T,直接加到集群中去,那么现在总容量就是8 x 1T = 8T 业界经常采用的方案，采购越来越多的普通服务器，性能比较一般，但是很多普通服务器组织在一起，就能构成强大的计算和存储能力 master节点 管理es集群的元数据,比如说索引的创建和删除,维护索引元数据,节点的增加和移除,维护集群的元数据 默认情况下,会自动选择出一台节点,作为master节点 节点对等的分布式架构每个es节点都能接收请求,接收请求后自动路由到可以处理该请求的shard,并收集返回数据.]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-4-聚合分析]]></title>
    <url>%2F2018%2F11%2F16%2FElasticsearch-4-%E8%81%9A%E5%90%88%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[上文中,添加了6个电影的document,接下来做这些document的聚合分析,统计等.上文添加的6个电影数据中都包含有genres 的一个数组 统计每个genres下的电影数量1234567891011GET /movies/movie/_search&#123; &quot;size&quot;: 0, // size不设置的话 hits中会把对进行聚合的所有数据返回. &quot;aggs&quot;: &#123; &quot;group_by_genres&quot;: &#123; // group_by_genres 是自定义的名字 &quot;terms&quot;: &#123; &quot;field&quot;: &quot;genres&quot; // 要做聚合的field &#125; &#125; &#125;&#125; 运行一下,会发现报错 如下:123456789101112131415161718192021222324252627282930&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Fielddata is disabled on text fields by default. Set fielddata=true on [genres] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory.&quot; &#125; ], &quot;type&quot;: &quot;search_phase_execution_exception&quot;, &quot;reason&quot;: &quot;all shards failed&quot;, &quot;phase&quot;: &quot;query&quot;, &quot;grouped&quot;: true, &quot;failed_shards&quot;: [ &#123; &quot;shard&quot;: 0, &quot;index&quot;: &quot;movies&quot;, &quot;node&quot;: &quot;f57uV91xS_GRTQS2Ho81rg&quot;, &quot;reason&quot;: &#123; &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Fielddata is disabled on text fields by default. Set fielddata=true on [genres] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory.&quot; &#125; &#125; ], &quot;caused_by&quot;: &#123; &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Fielddata is disabled on text fields by default. Set fielddata=true on [genres] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory.&quot; &#125; &#125;, &quot;status&quot;: 400&#125; 错误原因是:默认情况下，在文本字段上禁用Fielddata。在[genres]上设置fielddata=true，以便通过反转索引来加载内存中的fielddata。请注意，这可能会占用大量内存 这里我们需要将文本field的fielddata属性设置为true,具体原因之后再说.123456789PUT /movies/_mapping/movie&#123; &quot;properties&quot;: &#123; &quot;genres&quot;:&#123; &quot;type&quot;: &quot;text&quot;, &quot;fielddata&quot;: true &#125; &#125;&#125; 然后再执行上面的查询, 返回结果为:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&#123; &quot;took&quot;: 5, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 6, &quot;max_score&quot;: 0, &quot;hits&quot;: [] &#125;, &quot;aggregations&quot;: &#123; &quot;group_by_genres&quot;: &#123; &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ &#123; &quot;key&quot;: &quot;drama&quot;, &quot;doc_count&quot;: 4 &#125;, &#123; &quot;key&quot;: &quot;crime&quot;, &quot;doc_count&quot;: 3 &#125;, &#123; &quot;key&quot;: &quot;biography&quot;, &quot;doc_count&quot;: 2 &#125;, &#123; &quot;key&quot;: &quot;action&quot;, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: &quot;adventure&quot;, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: &quot;cirme&quot;, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: &quot;drame&quot;, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: &quot;mystery&quot;, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: &quot;thriller&quot;, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: &quot;war&quot;, &quot;doc_count&quot;: 1 &#125; ] &#125; &#125;&#125; 具体的聚合结果返回到了 aggregations 下的 buckets 下, key为每个genres下的元素, doc_count 是包含该key的电影数量. 对名称中包含kill的电影，计算每个genres下的电影数量12345678910111213141516GET /movies/movie/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;kill&quot; &#125; &#125;, &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_genres&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;genres&quot; &#125; &#125; &#125;&#125; 其实就是在上个查询的基础上加了一个query条件,先查询query,将返回的结果再进行聚合分析 先按genres分组,然后计算每个genres下的电影的年份的平均值123456789101112131415161718GET movies/movie/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_genres&quot;: &#123; // 自定义分组名称 &quot;terms&quot;: &#123; &quot;field&quot;: &quot;genres&quot; // 聚合genres &#125;, &quot;aggs&quot;: &#123; &quot;avg_year&quot;: &#123; // 在上面分组的基础上 在进行聚合分析 &quot;avg&quot;: &#123; // 计算平均值 &quot;field&quot;: &quot;year&quot; &#125; &#125; &#125; &#125; &#125;&#125; 平均值计算是按照每组里面的数据进行平均 计算每个genres下的电影的平均年份，并且按照平均年份降序排序123456789101112131415161718192021GET movies/movie/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_genres&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;genres&quot;, &quot;order&quot;: &#123; &quot;avg_year&quot;: &quot;desc&quot; &#125; &#125;, &quot;aggs&quot;: &#123; &quot;avg_year&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;year&quot; &#125; &#125; &#125; &#125; &#125;&#125; 在上一个分组计算平均值的基础上 在上层的terms里面加一个order 要排序的字段就是下面一层聚合计算平均值的名称”avg_year” 按照指定的年份范围区间进行分组，然后在每组内再按照genres进行分组，最后再计算每组的平均年份上文中添加的数据 电影年份有 1962 1972 1979 2007 2003, 用range来进行分组 分为1960-1970 1970-1980 2000-2010 三组12345678910111213141516171819202122232425GET /movies/movie/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_year&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &quot;year&quot;, &quot;ranges&quot;: [ &#123; &quot;from&quot;: 1960, &quot;to&quot;: 1970 &#125;, &#123; &quot;from&quot;: 1970, &quot;to&quot;: 1980 &#125;, &#123; &quot;from&quot;: 2000, &quot;to&quot;: 2010 &#125; ] &#125; &#125; &#125;&#125; 三组年份的电影分好以后,再往下一层按genres分一层,分好之后再往下聚合,用来计算平均值123456789101112131415161718192021222324252627282930313233343536373839GET /movies/movie/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_year&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &quot;year&quot;, &quot;ranges&quot;: [ &#123; &quot;from&quot;: 1960, &quot;to&quot;: 1970 &#125;, &#123; &quot;from&quot;: 1970, &quot;to&quot;: 1980 &#125;, &#123; &quot;from&quot;: 2000, &quot;to&quot;: 2010 &#125; ] &#125;, &quot;aggs&quot;: &#123; &quot;group_by_genres&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;genres&quot; &#125;, &quot;aggs&quot;: &#123; &quot;avg_year&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;year&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-3-花式查询]]></title>
    <url>%2F2018%2F11%2F16%2FElasticsearch-3-%E8%8A%B1%E5%BC%8F%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[新增语法:12345678910111213PUT indexName/typeName/id&#123; json数据&#125;或POST indexName/typeName&#123; json数据&#125;# 如果不指定id的话 es会自动分配一个id 示例下面添加了6个电影信息,索引名称是movies,类型名称是movie1234567891011121314151617181920212223242526272829303132333435363738394041424344454647PUT movies/movie/1&#123; &quot;title&quot;:&quot;The Godfather&quot;, &quot;director&quot;:&quot;Francis Ford Coppola&quot;, &quot;year&quot;:1972, &quot;genres&quot;: [&quot;Cirme&quot;,&quot;Drame&quot;]&#125;PUT movies/movie/2&#123; &quot;title&quot;: &quot;Lawrence of Arabia&quot;, &quot;director&quot;: &quot;David Lean&quot;, &quot;year&quot;: 1962, &quot;genres&quot;: [&quot;Adventure&quot;, &quot;Biography&quot;, &quot;Drama&quot;]&#125;PUT movies/movie/3&#123; &quot;title&quot;: &quot;To Kill a Mockingbird&quot;, &quot;director&quot;: &quot;Robert Mulligan&quot;, &quot;year&quot;: 1962, &quot;genres&quot;: [&quot;Crime&quot;, &quot;Drama&quot;, &quot;Mystery&quot;]&#125;PUT movies/movie/4&#123; &quot;title&quot;: &quot;Apocalypse Now&quot;, &quot;director&quot;: &quot;Francis Ford Coppola&quot;, &quot;year&quot;: 1979, &quot;genres&quot;: [&quot;Drama&quot;, &quot;War&quot;]&#125;PUT movies/movie/5&#123; &quot;title&quot;: &quot;Kill Bill: Vol. 1&quot;, &quot;director&quot;: &quot;Quentin Tarantino&quot;, &quot;year&quot;: 2003, &quot;genres&quot;: [&quot;Action&quot;, &quot;Crime&quot;, &quot;Thriller&quot;]&#125;PUT movies/movie/6&#123; &quot;title&quot;: &quot;The Assassination of Jesse James by the Coward Robert Ford&quot;, &quot;director&quot;: &quot;Andrew Dominik&quot;, &quot;year&quot;: 2007, &quot;genres&quot;: [&quot;Biography&quot;, &quot;Crime&quot;, &quot;Drama&quot;]&#125; 添加完毕之后,通过搜索查询一下这几部电影 (使用_search端点)语法:12GET [index_name]/[type_name]/_search # index_name和type_name都是可选的 示例123GET _search //搜索所有索引和所有类型。GET movies/_search //在电影索引中搜索所有类型GET movies/movie/_search //在电影索引中显式搜索电影类型的文档 query DSLDSL: Domain Specified Language ,特定领域的语言http request body: 请求体,可以用json格式来构建查询语法,比较方便,可以构建各种复杂语法. 查询所有的电影1234GET movies/movie/_search&#123; &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;&#125; 查询名称包含kill的电影,同时年份按照降序排序12345678910111213GET movies/movie/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;kill&quot; &#125; &#125;, &quot;sort&quot;: [ &#123; &quot;year&quot;: &quot;desc&quot; &#125; ]&#125; 分页查询,假设每页显示一条数据,现在查询第二页123456GET movies/movie/_search&#123; &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;, &quot;from&quot;: 1, &quot;size&quot;: 1&#125; 指定查询出来的电影只要名称和年份12345GET movies/movie/_search&#123; &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;, &quot;_source&quot;: [&quot;title&quot;,&quot;year&quot;]&#125; query filter 过滤器查询电影名称包含kill,而且年份大于2000年的电影12345678910111213141516171819GET /movies/movie/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;:&#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;kill&quot; &#125; &#125;, &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;year&quot;: &#123; &quot;gt&quot;: 2000 &#125; &#125; &#125; &#125; &#125;&#125; full-text search (全文检索)123456GET /movies/movie/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123; &quot;title&quot;: &quot;Kill Bill Lawrence&quot; &#125;&#125;&#125; 首先 将 /movies/movie/下面的所有数据的title的值拆分,建立倒排索引,然后搜索关键字会被拆分为Kill和Bill和Lawrence 然后在倒排索引中检索对应的数据 全文检索会将输入的关键字拆解开来，去倒排索引里面去一一匹配，只要能匹配上任意一个拆解后的单词，就可以作为结果返回 phrase search 短语搜索12345678GET /movies/movie/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;title&quot;: &quot;kill&quot; &#125; &#125;&#125; 跟全文检索相反,要求输入关键字 必须在指定的字段文本中,完全包含一模一样的,才可以算匹配,才能做为返回结果.比如 查询kill 会返回 “Kill Bill: Vol. 1” 和 “To Kill a Mockingbird” 查询kill bill 只会返回 “Kill Bill: Vol. 1” highlight search 高亮搜索结果GET /movies/movie/_search{ “query”: { “match”: { “title”: “kill” } }, “highlight”: { “fields”: { “title”:{} } }} 返回会在 highlight &gt; title 中 将关键字加 &lt;em&gt;&lt;/em&gt; 标签 搜索结果说明 took：耗费了几毫秒 timed_out：是否超时 _shards：一个搜索请求会达到一个index的所有primary shard上,当然 每个primary shard都可能有一个或多个replica shard,所以请求也可以到primary shard的其中一个replica shard上去,shards fail的条件(primary和replica全部挂掉)，不影响其他shard. hits.total：查询结果的数量 hits.max_score：本次搜索的所有结果中，最大的相关度分数是多少，每一条document对于search的相关度，越相关，_score分数越大，排位越靠前 hits.hits：默认查询前10条数据,完整数据,_score 降序排序 time_out机制详解查询默认是没有timeout的,可以手动指定1GET /_search?timeout=10ms 意思就是在timeout的时间范围内,将搜索到的所有结果直接返回给客户端,不需要等数据全部查到后返回,确保一次搜索请求可以在指定的时间内完成,为一些时间敏感的搜索应用提供良好的支持 代码地址 代码地址]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-2-集群状态检查和CRUD操作]]></title>
    <url>%2F2018%2F11%2F16%2FElasticsearch-2-%E9%9B%86%E7%BE%A4%E7%8A%B6%E6%80%81%E6%A3%80%E6%9F%A5%E5%92%8CCRUD%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[检查集群的健康状态Kibana中1GET _cat/health?v 返回值12epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1537168122 15:08:42 elasticsearch yellow 1 1 1 1 0 0 1 0 - 50.0% status:集群的健康状况green:每个索引的primary shard和replica shard都是active状态的yellow:每个缩影的primary shard都是active状态的,但是部分replica shard不是active状态,处于不可用的状态.red:不是所有索引的primary shard都是active状态,部分索引有数据丢失了 当只启动一个es的时候 集群状态是yellow的,，就启动了一个es进程，相当于就只有一个node。现在es中有一个index，就是kibana自己内置建立的index。由于默认的配置是给每个index分配5个primary shard和5个replica shard，而且primary shard和replica shard不能在同一台机器上（为了容错）。现在kibana自己建立的index是1个primary shard和1个replica shard。当前就一个node，所以只有1个primary shard被分配了和启动了，但是一个replica shard没有第二台机器去启动。此时只要启动第二个es进程，就会在es集群中有2个node，然后那1个replica shard就会自动分配过去，然后cluster status就会变成green状态。 索引管理快速查看集群中有哪些索引:1GET /_cat/indices?v 返回值12health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open .kibana rUm9n9wMRQCCrRDEhqneBg 1 1 1 0 3.1kb 3.1kb 创建索引1PUT /test_index?pretty 删除索引1DELETE /test_index?pretty document的CRUD操作新增document 建立索引12345678910111213141516171819PUT /index_name/type_name/id&#123; json数据&#125;// 返回值&#123; &quot;_index&quot;: &quot;index_name&quot;, &quot;_type&quot;: &quot;type_name&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true&#125; es会自动建立index和type，不需要提前创建，而且es默认会对document每个field都建立倒排索引，让其可以被搜索 检索/查询文档1234567891011121314151617181920GET index_name/type_name/id// 返回值&#123; &quot;_index&quot;: &quot;index_name&quot;, &quot;_type&quot;: &quot;type_name&quot;, &quot;_id&quot;: &quot;id&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;gaolujie yagao&quot;, &quot;desc&quot;: &quot;gaoxiao meibai&quot;, &quot;price&quot;: 30, &quot;producer&quot;: &quot;gaolujie producer&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot; ] &#125;&#125; 更新document全量替换123456PUT /index_name/type_name/id&#123; json数据&#125;// 不做更新的filed也需要传过去 上面这个操作是全量替换,其实是es先把旧的数据标记为deleted,不做物理删除,然后再创建一个新的document出来,id也和原来的一样,当es数据量增大时,es才会去删除被标记为deleted的数据,来释放空间 那么如何强制创建呢,就是上面这个操作不想去更新,就是想去再创建一个新的document,那么这时候可以在请求后面加一个参数 ?_create,但是执行时候发现这样会报错,因为这个id已经存在了引起冲突,所以会报错 partial update12345678POST /index_name/type_name/id/_update&#123; &quot;doc&quot;:&#123; &quot;需要更新的列&quot;:&quot;值&quot; &#125;&#125;// 上面这个更新看起来就比较方便了,每次只需要传递少数的发生修改的filed过去即可,不需要将全量的document数据发送过去. 两者对比我们使用全量替换的时候,当我们只需要修改document中其中某一个字段的时候必须知道其他字段的值,这时候我们需要进行一次查询,然后将不需要修改的字段原封不动的写入到语句中去,可以很容易的看出进行一次数据修改,需要用于先去查询,然后更新再写回到es中去,耗费的时间相对较长,而且在写入数据的时候,可能别人已经对数据进行修改了,容易产生并发冲突 然后我们来看一下partial update,其实partial update的执行和全量替换是一样的,也是先获取document,然后将传过来的filed更新到document中,将老的document标记为deleted,用新的数据创建新的document, 但是相较于全量替换,partial update的所有查询修改都是发生在es内部的,操作基本都是毫秒级别的,耗费的时间相对较小,并发冲突的可能性也就相对较小. 总结partial update与全量替换的执行步骤其实是一致的,但是partial update所有的查询和修改操作都是在es内部的shard中进行的,避免了网络数据传输的开销,提升 了性能. 第二减少了查询和修改中的时间间隔,有效减少了并发冲突. 删除document1DELETE /index_name/type_name/id 这里的删除也是做的逻辑删除,es把要删除的document标记为deleted状态,也是在存储空间不够的时候es才会去做物理删除来释放空间]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-1-Windows下安装Es]]></title>
    <url>%2F2018%2F11%2F16%2FElasticsearch-1-Windows%E4%B8%8B%E5%AE%89%E8%A3%85Es%2F</url>
    <content type="text"><![CDATA[下载elasticsearchelasticsearch-5.2.0.zip 解压 cmd进入bin目录,启动1elasticsearch.bat 检查是否启动成功1http://localhost:9200/?pretty 返回值12345678910111213&#123; &quot;name&quot; : &quot;f57uV91&quot;, // 节点名称 &quot;cluster_name&quot; : &quot;elasticsearch&quot;, // 所在集群名称 &quot;cluster_uuid&quot; : &quot;uyiZiUqnSSaV-eazKkv_sg&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;5.2.0&quot;, // 版本号 &quot;build_hash&quot; : &quot;24e05b9&quot;, &quot;build_date&quot; : &quot;2017-01-24T19:52:35.800Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;6.4.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 下载Kibanakibana-5.2.0-windows-x86.zip 解压 进入bin目录,启动kibana.bat localhost:5601/ 进入Dev Tools]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-0-核心概念]]></title>
    <url>%2F2018%2F11%2F16%2FElasticsearch-0-%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[全文检索把要搜索的内容 进行分词储存为倒排索引, 搜索的时候,去扫描的是内容中的所有关键词而不是去扫描内容本身内容中能拆分出来多少词 倒排索引中就会有多少行 先遍历倒排索引中的关键词,然后去数据源中找到数据返回 Lucene封装了建立倒排索引,以及搜索的代码,包括各种算法, 提供了java使用的api,用Lucene可以将已有的数据建立索引,Lucene会在本地磁盘上组织索引的数据结构,另外可以用Lucene提供的提供的功能和api对磁盘上的索引数据进行搜索 ElasticsearchLucene索引是建立在磁盘上的,当数据量大的时候,建立的索引数据占用的空间也会越来越大, 可能会需要多台机器来存放索引数据,这时前端搜索关键字的时候,就需要去判断去哪台机器上的索引搜索,而且服务器宕机的情况下索引数据可能会丢失等.这个时候就需要Elasticsearch,ES底层封装了Lucene,可以配置多个ES节点优点: 自动维护数据的分布到多个节点的索引建立,还有搜索请求分布到多个节点的执行 自动维护数据的冗余副本,保证某些机器宕机之后不会丢失数据 封装了更多的高级功能,便于快速开发应用,提供更复杂的搜索功能,聚合分析的功能,基于地理位置的搜索等 功能: 分布式的搜索引擎和数据分析引擎 数据分析:比如查询一个电商网站中,某一类商品销量前10的店铺;某类商品中一个月内访问量最高的商品等 全文检索,结构化检索,数据分析 结构化检索:比如搜索某一类的商品有哪些 对海量的数据进行实时的处理 ES可以自动将海量的数据分散到多台服务器上存储和检索 进实时是指秒级别的数据搜索和分析 特点: 可以作为一个大型分布式集群技术,处理PB级别的数据, 也可以运行在单机上 将全文检索和数据分析合并在了一起 对用户而言 开箱即用 对传统数据库的补充,提供了很多数据库不能提供的功能,如全文检索,同义词处理,相关度排名,复杂数据分析,海量数据的近实时处理等 核心概念Near RealTime(NRT): 近实时, 从数据写入到可以被搜索到大概有1s的延迟; 基于ES执行搜索和分析可以达到秒级 Cluster: 集群,包含多个节点,节点可以通过配置集群名称来标识是属于哪个集群的 Node:节点 集群中的一个节点, 节点也有名称(默认是随机分配的), 默认节点会被加入到名为”elasticsearch”的集群 Document&amp;field: 文档,ES中的最小数据单元,一个document可以是任意一条数据, 数据结构通常是JSON 一个document中会有多个field,每个field就是json中的一个字段 Index:索引,包含一堆相似结构的文档数据, 比如有一个订单索引,商品分类索引,索引会有一个名称,一个index代表了一类类似的或者相同的document,index可以包含多个document,比如创建一个product index(商品索引),里面就可能存放了所有的商品数据 Type:类型,每个索引里可以有一个或多个type, type是index中的一个逻辑分类,一个type下的document都有相同的filed shard:单机无法存储大量数据,ES可以将一个索引中的数据拆分成多个shard,分布在多台服务器上存储.有了shard就可以横向扩展,当数据量增加的时候,直接再增加一个es节点就可以了,搜索和分析的操作分布到多台服务器上执行可以提高吞吐量和性能. replica: 服务器可能随时故障或宕机,此时shard节点会丢失,因此可以为每个shard创建多个replica副本, replica可以在shard宕机的情况下提供备用服务 同时可以提升搜索操作的吞吐量和性能.primary shard(建立索引时一次设置,不能修改,默认5个)replica shard(随时修改数量,默认1个&lt;对应每个primary shard的1个&gt;), 默认每个索引10个shard,5个 primary shard,5个replica shard 最小的高可用配置是两台服务器 ES对应到数据库document —&gt; 行type —&gt; 表index —&gt; 库]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
</search>
